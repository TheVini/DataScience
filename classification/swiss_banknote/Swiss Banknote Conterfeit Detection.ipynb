{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e5696532",
   "metadata": {},
   "source": [
    "Exercício baseado no problema publicado no Kaggle: https://www.kaggle.com/chrizzles/swiss-banknote-conterfeit-detection\n",
    "\n",
    "**Objetivo:** desenvolver um modelo de classificação capaz de identificar dinheiro falso baseado nas dimensões de uma nota\n",
    "\n",
    "**Proposta:**\n",
    "- Efetuar uma análise exploratória dos dados do dataset\n",
    "- Identificar possíveis enviesamento dos dados\n",
    "- Realizar testes de hipóteses analisando a variância dos dados\n",
    "- Testes de normalidade\n",
    "- Identificar possíveis correlações\n",
    "- Se necessário, aplicar técnicas de geração de amostras artificiais\n",
    "- Aplicar técnicas de amostragem que diminuam ao máximo um possível overfitting\n",
    "- Aplicar técnicas de normalização e regularização, onde aplicável\n",
    "- Descobrir qual algoritmo tem o melhor desempenho entre Naïve Bayes, Regressão Logística e Árvore de Decisão\n",
    "- Usar técnicas de validação cruzada\n",
    "- Validar resultado com matriz de confusão\n",
    "- Analisar o grau de variação entre os resutados de teste\n",
    "\n",
    "Contato pelo Linkedin: https://bit.ly/3tsOnU3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c2c804bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import zipfile\n",
    "import os\n",
    "import statsmodels.api as sm\n",
    "import scipy.stats as stats\n",
    "from matplotlib import pyplot as plt\n",
    "from sklearn.model_selection import train_test_split, cross_val_score, KFold\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from scipy.stats import shapiro\n",
    "from scipy.stats import norm\n",
    "import warnings\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "abs_path = os.getcwd()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b565541",
   "metadata": {},
   "source": [
    "# 1. Obtém o dataset através da API do Kaggle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "28a252d7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There is a parquet file!!!\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>conterfeit</th>\n",
       "      <th>Length</th>\n",
       "      <th>Left</th>\n",
       "      <th>Right</th>\n",
       "      <th>Bottom</th>\n",
       "      <th>Top</th>\n",
       "      <th>Diagonal</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>214.8</td>\n",
       "      <td>131.0</td>\n",
       "      <td>131.1</td>\n",
       "      <td>9.0</td>\n",
       "      <td>9.7</td>\n",
       "      <td>141.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>214.6</td>\n",
       "      <td>129.7</td>\n",
       "      <td>129.7</td>\n",
       "      <td>8.1</td>\n",
       "      <td>9.5</td>\n",
       "      <td>141.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>214.8</td>\n",
       "      <td>129.7</td>\n",
       "      <td>129.7</td>\n",
       "      <td>8.7</td>\n",
       "      <td>9.6</td>\n",
       "      <td>142.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>214.8</td>\n",
       "      <td>129.7</td>\n",
       "      <td>129.6</td>\n",
       "      <td>7.5</td>\n",
       "      <td>10.4</td>\n",
       "      <td>142.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>215.0</td>\n",
       "      <td>129.6</td>\n",
       "      <td>129.7</td>\n",
       "      <td>10.4</td>\n",
       "      <td>7.7</td>\n",
       "      <td>141.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>195</th>\n",
       "      <td>1</td>\n",
       "      <td>215.0</td>\n",
       "      <td>130.4</td>\n",
       "      <td>130.3</td>\n",
       "      <td>9.9</td>\n",
       "      <td>12.1</td>\n",
       "      <td>139.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>196</th>\n",
       "      <td>1</td>\n",
       "      <td>215.1</td>\n",
       "      <td>130.3</td>\n",
       "      <td>129.9</td>\n",
       "      <td>10.3</td>\n",
       "      <td>11.5</td>\n",
       "      <td>139.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>197</th>\n",
       "      <td>1</td>\n",
       "      <td>214.8</td>\n",
       "      <td>130.3</td>\n",
       "      <td>130.4</td>\n",
       "      <td>10.6</td>\n",
       "      <td>11.1</td>\n",
       "      <td>140.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>198</th>\n",
       "      <td>1</td>\n",
       "      <td>214.7</td>\n",
       "      <td>130.7</td>\n",
       "      <td>130.8</td>\n",
       "      <td>11.2</td>\n",
       "      <td>11.2</td>\n",
       "      <td>139.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>199</th>\n",
       "      <td>1</td>\n",
       "      <td>214.3</td>\n",
       "      <td>129.9</td>\n",
       "      <td>129.9</td>\n",
       "      <td>10.2</td>\n",
       "      <td>11.5</td>\n",
       "      <td>139.6</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>200 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     conterfeit  Length   Left  Right  Bottom   Top  Diagonal\n",
       "0             0   214.8  131.0  131.1     9.0   9.7     141.0\n",
       "1             0   214.6  129.7  129.7     8.1   9.5     141.7\n",
       "2             0   214.8  129.7  129.7     8.7   9.6     142.2\n",
       "3             0   214.8  129.7  129.6     7.5  10.4     142.0\n",
       "4             0   215.0  129.6  129.7    10.4   7.7     141.8\n",
       "..          ...     ...    ...    ...     ...   ...       ...\n",
       "195           1   215.0  130.4  130.3     9.9  12.1     139.6\n",
       "196           1   215.1  130.3  129.9    10.3  11.5     139.7\n",
       "197           1   214.8  130.3  130.4    10.6  11.1     140.0\n",
       "198           1   214.7  130.7  130.8    11.2  11.2     139.4\n",
       "199           1   214.3  129.9  129.9    10.2  11.5     139.6\n",
       "\n",
       "[200 rows x 7 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "parquet_file = \"banknotes.parquet\"\n",
    "csv_file = \"banknotes.csv\"\n",
    "zip_file_name = \"swiss-banknote-conterfeit-detection.zip\"\n",
    "\n",
    "if os.path.isfile(parquet_file):\n",
    "    print (\"There is a parquet file!!!\")\n",
    "    dataset = pd.read_parquet(parquet_file)\n",
    "else:\n",
    "    \"\"\"\n",
    "    Obtém o dataset compactado em .zip, \n",
    "    extrai o arquivo .csv,\n",
    "    deleta o arquivo .zip\n",
    "    carrega o arquivo no jupyter,\n",
    "    deleta o arquivo .csv,\n",
    "    e gera um arquivo .parquet\n",
    "    \"\"\"\n",
    "    print (\"There is no file\")\n",
    "    !kaggle datasets download -d chrizzles/swiss-banknote-conterfeit-detection\n",
    "    with zipfile.ZipFile(zip_file_name,\"r\") as zip_ref:\n",
    "        zip_ref.extractall(abs_path)\n",
    "    os.remove(file_name)\n",
    "    dataset = pd.read_csv(csv_file)\n",
    "    dataset.to_parquet(parquet_file, engine='pyarrow')\n",
    "    os.remove(csv_file)\n",
    "    \n",
    "dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12ec0e33",
   "metadata": {},
   "source": [
    "# 2. Análise Exploratória dos Dados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "bd21c78c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(200, 7)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9cb9a515",
   "metadata": {},
   "source": [
    "**análise:** através do resultado \"false\" obtido abaixo, foi provado que:\n",
    "- Todos os elementos possuem todos os dados, portanto não se faz necessário a remoção de nenhum deles da base de dados, bem como não se faz necessário utilizar nenhuma técnica de preenchimento de dado (ex.: interpolação, média, moda e etc.).\n",
    "- Não há colunas com excesso de dados nulos, portanto, se for necessário eliminar alguma coluna, não será por este motivo, mas simpor algum outro como baixa correlação com a variável de resposta."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d66fcda6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "conterfeit    0\n",
       "Length        0\n",
       "Left          0\n",
       "Right         0\n",
       "Bottom        0\n",
       "Top           0\n",
       "Diagonal      0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "53b522a6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "conterfeit      int64\n",
       "Length        float64\n",
       "Left          float64\n",
       "Right         float64\n",
       "Bottom        float64\n",
       "Top           float64\n",
       "Diagonal      float64\n",
       "dtype: object"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c64abd89",
   "metadata": {},
   "source": [
    "**análise:** abaixo é possível notar a necessidade da normalização das variáveis explicativas, e que elas são variáveis contínuas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5827e13d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>conterfeit</th>\n",
       "      <th>Length</th>\n",
       "      <th>Left</th>\n",
       "      <th>Right</th>\n",
       "      <th>Bottom</th>\n",
       "      <th>Top</th>\n",
       "      <th>Diagonal</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>200.000000</td>\n",
       "      <td>200.000000</td>\n",
       "      <td>200.000000</td>\n",
       "      <td>200.000000</td>\n",
       "      <td>200.000000</td>\n",
       "      <td>200.000000</td>\n",
       "      <td>200.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.500000</td>\n",
       "      <td>214.896000</td>\n",
       "      <td>130.121500</td>\n",
       "      <td>129.956500</td>\n",
       "      <td>9.417500</td>\n",
       "      <td>10.650500</td>\n",
       "      <td>140.483500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.501255</td>\n",
       "      <td>0.376554</td>\n",
       "      <td>0.361026</td>\n",
       "      <td>0.404072</td>\n",
       "      <td>1.444603</td>\n",
       "      <td>0.802947</td>\n",
       "      <td>1.152266</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>213.800000</td>\n",
       "      <td>129.000000</td>\n",
       "      <td>129.000000</td>\n",
       "      <td>7.200000</td>\n",
       "      <td>7.700000</td>\n",
       "      <td>137.800000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>214.600000</td>\n",
       "      <td>129.900000</td>\n",
       "      <td>129.700000</td>\n",
       "      <td>8.200000</td>\n",
       "      <td>10.100000</td>\n",
       "      <td>139.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>0.500000</td>\n",
       "      <td>214.900000</td>\n",
       "      <td>130.200000</td>\n",
       "      <td>130.000000</td>\n",
       "      <td>9.100000</td>\n",
       "      <td>10.600000</td>\n",
       "      <td>140.450000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>215.100000</td>\n",
       "      <td>130.400000</td>\n",
       "      <td>130.225000</td>\n",
       "      <td>10.600000</td>\n",
       "      <td>11.200000</td>\n",
       "      <td>141.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>216.300000</td>\n",
       "      <td>131.000000</td>\n",
       "      <td>131.100000</td>\n",
       "      <td>12.700000</td>\n",
       "      <td>12.300000</td>\n",
       "      <td>142.400000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       conterfeit      Length        Left       Right      Bottom         Top  \\\n",
       "count  200.000000  200.000000  200.000000  200.000000  200.000000  200.000000   \n",
       "mean     0.500000  214.896000  130.121500  129.956500    9.417500   10.650500   \n",
       "std      0.501255    0.376554    0.361026    0.404072    1.444603    0.802947   \n",
       "min      0.000000  213.800000  129.000000  129.000000    7.200000    7.700000   \n",
       "25%      0.000000  214.600000  129.900000  129.700000    8.200000   10.100000   \n",
       "50%      0.500000  214.900000  130.200000  130.000000    9.100000   10.600000   \n",
       "75%      1.000000  215.100000  130.400000  130.225000   10.600000   11.200000   \n",
       "max      1.000000  216.300000  131.000000  131.100000   12.700000   12.300000   \n",
       "\n",
       "         Diagonal  \n",
       "count  200.000000  \n",
       "mean   140.483500  \n",
       "std      1.152266  \n",
       "min    137.800000  \n",
       "25%    139.500000  \n",
       "50%    140.450000  \n",
       "75%    141.500000  \n",
       "max    142.400000  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26c53ee0",
   "metadata": {},
   "source": [
    "**análise:** a coluna da variável de resposta, 'conterfeit', está perfeitamente balanceada entre as duas classes fornecidas. Portanto, não é necessário nenhuma técnica para remover ou criar elementos artificiais devido a algum desbalanceamento entre as classes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0d46bc4a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([0, 1], dtype=int64), array([100, 100], dtype=int64))"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.unique(dataset['conterfeit'], return_counts=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92ae2842",
   "metadata": {},
   "source": [
    "**análise:** os gráficos de distribuição abaixo também provam que se faz necessário a normalização das variáveis explicativas. Além de mostrar a variedade de tipos de distribuições entre elas: bimodal, normal, enviesada à direita e à esquerda"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ea516b99",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>conterfeit</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>195</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>196</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>197</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>198</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>199</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>200 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     conterfeit\n",
       "0             0\n",
       "1             0\n",
       "2             0\n",
       "3             0\n",
       "4             0\n",
       "..          ...\n",
       "195           1\n",
       "196           1\n",
       "197           1\n",
       "198           1\n",
       "199           1\n",
       "\n",
       "[200 rows x 1 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.iloc[:,:1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "dd43aee6",
   "metadata": {
    "code_folding": [],
    "scrolled": false
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'x' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-8-272ab7815afe>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfigure\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfigsize\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m20\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m10\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[1;32mfor\u001b[0m \u001b[0mcount\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcolumn\u001b[0m \u001b[1;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m     \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msubplot\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m/\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcount\u001b[0m\u001b[1;33m+\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m     \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtitle\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcolumn\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m     \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msubplot\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msns\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdistplot\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdataset\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mcolumn\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'x' is not defined"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1440x720 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "x = dataset.iloc[:,1:]\n",
    "y = dataset.iloc[:,:1]\n",
    "\n",
    "plt.figure(figsize=(20,10))\n",
    "for count, column in enumerate(x.columns):\n",
    "    plt.subplot(2, len(x.columns)/2, count+1)\n",
    "    plt.title(column)\n",
    "    plt.subplot(sns.distplot(dataset[column]))\n",
    "plt.show()\n",
    "plt.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf803ebb",
   "metadata": {},
   "source": [
    "**análise:** os box plots abaixo mostram que existem alguns outliers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d988a4f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(20,10))\n",
    "for count, column in enumerate(x.columns):\n",
    "    plt.subplot(2, len(x.columns)/2, count+1)\n",
    "    plt.title(column)\n",
    "    plt.subplot(sns.boxplot(data=dataset[column]))\n",
    "plt.show()\n",
    "plt.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c57e0987",
   "metadata": {},
   "source": [
    "**análise:** quanto a normalidade, mais detalhes podem ser obtidos no gráfico QQ abaixo com o valor de alpha ajustado para 95%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0020248a",
   "metadata": {
    "code_folding": [],
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "def isNormalDist(column, p):\n",
    "    alpha = 0.05\n",
    "    afirmative_text = 'A coluna {} é uma distribuição normal'.format(column)\n",
    "    negative_text = 'A coluna {} não é uma distribuição normal'.format(column)\n",
    "    return afirmative_text if p > alpha else negative_text\n",
    "\n",
    "for column in x.columns:\n",
    "    _, p = shapiro(dataset[column])\n",
    "    fig = sm.qqplot(dataset[column], stats.t, distargs=(4,), line = 's')\n",
    "    plt.title(isNormalDist(column, p))\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9bfe5859",
   "metadata": {},
   "source": [
    "# 3. Treino do modelo - sem normalização, sem estudo de correlações, sem tratamento dos enviesamentos e sem testes de hipóteses, apenas para existir uma referência de melhoria de modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49a7bda5",
   "metadata": {},
   "outputs": [],
   "source": [
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53804e58",
   "metadata": {},
   "outputs": [],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "602add79",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def train(x, y):\n",
    "    resultados_naive_bayes = []\n",
    "    resultados_logistica = []\n",
    "    resultados_forest = []\n",
    "    for i in range(10):\n",
    "        x_train, x_test, y_train, y_test = train_test_split(x, \n",
    "                                                            y, \n",
    "                                                            test_size=0.3,\n",
    "                                                            stratify = y,\n",
    "                                                            random_state = i)\n",
    "        naive_bayes = GaussianNB()\n",
    "        naive_bayes.fit(x_train, y_train)\n",
    "        resultados_naive_bayes.append(accuracy_score(y_test, naive_bayes.predict(x_test)))\n",
    "\n",
    "        logistica = LogisticRegression()\n",
    "        logistica.fit(x_train, y_train)\n",
    "        resultados_logistica.append(accuracy_score(y_test, logistica.predict(x_test)))\n",
    "\n",
    "        random_forest = RandomForestClassifier()\n",
    "        random_forest.fit(x_train, y_train)\n",
    "        resultados_forest.append(accuracy_score(y_test, random_forest.predict(x_test)))\n",
    "    \n",
    "    return np.array(resultados_naive_bayes), np.array(resultados_logistica), np.array(resultados_forest)\n",
    "\n",
    "resultados_naive_bayes, resultados_logistica, resultados_forest = train(x, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55dbf69a",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Média: Naïve Bayes {:.5}, Regressão Log. {:.5}, Árvore de decisão {:.5}\".format(resultados_naive_bayes.mean(), resultados_logistica.mean(), resultados_forest.mean()))\n",
    "print(\"Desvio Padrão: Naïve Bayes {:.5}, Regressão Log. {:.5}, Árvore de decisão {:.5}\".format(np.std(resultados_naive_bayes), np.std(resultados_logistica), np.std(resultados_forest)))\n",
    "print(\"Coeficiente de variação: Naïve Bayes {:.5}, Regressão Log. {:.5}, Árvore de decisão {:.5}\".format(stats.variation(resultados_naive_bayes), stats.variation(resultados_logistica), stats.variation(resultados_forest)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d39419b",
   "metadata": {},
   "source": [
    "**Intervalo de confiança**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "957fc29b",
   "metadata": {},
   "outputs": [],
   "source": [
    "intervalos_naive = norm.interval(0.95, resultados_naive_bayes.mean(),stats.sem(resultados_naive_bayes))\n",
    "intervalos_log = norm.interval(0.95, resultados_logistica.mean(),stats.sem(resultados_logistica))\n",
    "intervalos_forest = norm.interval(0.95, resultados_forest.mean(),stats.sem(resultados_forest))\n",
    "\n",
    "intervalos_naive, intervalos_log, intervalos_forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2de0fee",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(20,5))\n",
    "plt.subplot(1, 3, 1)\n",
    "plt.title(\"Naïve Bayes\")\n",
    "plt.subplot(sns.distplot(resultados_naive_bayes, color=\"red\", label=\"Naïve Bayes\", hist=False, kde=True))\n",
    "plt.legend();\n",
    "\n",
    "plt.subplot(1, 3, 2)\n",
    "plt.title(\"Regressão Logística\")\n",
    "plt.subplot(sns.distplot(resultados_logistica, color=\"green\", label=\"Reg. Logística\", hist=False, kde=True))\n",
    "plt.legend();\n",
    "\n",
    "plt.subplot(1, 3, 3)\n",
    "plt.title(\"Árvore de Decisão\")\n",
    "plt.subplot(sns.distplot(resultados_forest, color=\"blue\", label=\"Random Forest\", hist=False, kde=True))\n",
    "plt.legend();"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dde46e52",
   "metadata": {},
   "source": [
    "# 4. Validação dos modelos com K-Fold - sem normalização, sem estudo de correlações, sem tratamento dos enviesamentos e sem testes de hipóteses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d440c66d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_kfold(x, y):\n",
    "    resultados_naive_bayes = []\n",
    "    resultados_logistica = []\n",
    "    resultados_forest = []\n",
    "\n",
    "    for i in range(10):\n",
    "        kfold = KFold(n_splits = 10, shuffle = True, random_state = i)\n",
    "\n",
    "        naive_bayes = GaussianNB()\n",
    "        scores = cross_val_score(naive_bayes, x, y, cv = kfold)\n",
    "        resultados_naive_bayes.append(scores.mean())\n",
    "\n",
    "        logistica = LogisticRegression()\n",
    "        scores = cross_val_score(logistica, x, y, cv = kfold)\n",
    "        resultados_logistica.append(scores.mean())\n",
    "\n",
    "        random_forest = RandomForestClassifier()\n",
    "        scores = cross_val_score(random_forest, x, y, cv = kfold)\n",
    "        resultados_forest.append(scores.mean())\n",
    "        \n",
    "    return np.array(resultados_naive_bayes), np.array(resultados_logistica), np.array(resultados_forest)\n",
    "\n",
    "resultados_naive_bayes_kfold, resultados_logistica_kfold, resultados_forest_kfold = train_kfold(x, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ddadb43",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Média: Naïve Bayes {:.5}, Regressão Log. {:.5}, Árvore de decisão {:.5}\".format(resultados_naive_bayes_kfold.mean(), resultados_logistica_kfold.mean(), resultados_forest_kfold.mean()))\n",
    "print(\"Desvio Padrão: Naïve Bayes {:.5}, Regressão Log. {:.5}, Árvore de decisão {:.5}\".format(np.std(resultados_naive_bayes_kfold), np.std(resultados_logistica_kfold), np.std(resultados_forest_kfold)))\n",
    "print(\"Coeficiente de variação: Naïve Bayes {:.5}, Regressão Log. {:.5}, Árvore de decisão {:.5}\".format(stats.variation(resultados_naive_bayes_kfold), stats.variation(resultados_logistica_kfold), stats.variation(resultados_forest_kfold)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a64774b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "intervalos_naive = norm.interval(0.95, resultados_naive_bayes_kfold.mean(),stats.sem(resultados_naive_bayes_kfold))\n",
    "intervalos_log = norm.interval(0.95, resultados_logistica_kfold.mean(),stats.sem(resultados_logistica_kfold))\n",
    "intervalos_forest = norm.interval(0.95, resultados_forest_kfold.mean(),stats.sem(resultados_forest_kfold))\n",
    "\n",
    "intervalos_naive, intervalos_log, intervalos_forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b400b01",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(20,5))\n",
    "plt.subplot(1, 3, 1)\n",
    "plt.title(\"Naïve Bayes\")\n",
    "plt.subplot(sns.distplot(resultados_naive_bayes_kfold, color=\"red\", label=\"Naïve Bayes\", hist=False, kde=True))\n",
    "plt.legend();\n",
    "\n",
    "plt.subplot(1, 3, 2)\n",
    "plt.title(\"Regressão Logística\")\n",
    "plt.subplot(sns.distplot(resultados_logistica_kfold, color=\"green\", label=\"Reg. Logística\", hist=False, kde=True))\n",
    "plt.legend();\n",
    "\n",
    "plt.subplot(1, 3, 3)\n",
    "plt.title(\"Árvore de Decisão\")\n",
    "plt.subplot(sns.distplot(resultados_forest_kfold, color=\"blue\", label=\"Random Forest\", hist=False, kde=True))\n",
    "plt.legend();"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb2748cd",
   "metadata": {},
   "source": [
    "# 5. Treino do modelo com normalização"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "450f9b93",
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize_and_train(x, y):\n",
    "    resultados_naive_bayes = []\n",
    "    resultados_logistica = []\n",
    "    resultados_forest = []\n",
    "    for i in range(10):\n",
    "        x_train, x_test, y_train, y_test = train_test_split(x, \n",
    "                                                            y, \n",
    "                                                            test_size=0.3,\n",
    "                                                            stratify = y,\n",
    "                                                            random_state = i)\n",
    "        for i in range(x.shape[1]):\n",
    "            z_score_train = StandardScaler()\n",
    "            z_score_test = StandardScaler()\n",
    "\n",
    "            x_train[x_train.columns[i]] = z_score_train.fit_transform(x_train.iloc[:,i:i+1])\n",
    "            x_test[x_test.columns[i]] = z_score_test.fit_transform(x_test.iloc[:,i:i+1])\n",
    "        \n",
    "        naive_bayes = GaussianNB()\n",
    "        naive_bayes.fit(x_train, y_train)\n",
    "        resultados_naive_bayes.append(accuracy_score(y_test, naive_bayes.predict(x_test)))\n",
    "        \n",
    "        logistica = LogisticRegression()\n",
    "        logistica.fit(x_train, y_train)\n",
    "        resultados_logistica.append(accuracy_score(y_test, logistica.predict(x_test)))\n",
    "\n",
    "        random_forest = RandomForestClassifier()\n",
    "        random_forest.fit(x_train, y_train)\n",
    "        resultados_forest.append(accuracy_score(y_test, random_forest.predict(x_test)))\n",
    "    return [np.array(resultados_naive_bayes), \n",
    "            np.array(resultados_logistica), \n",
    "            np.array(resultados_forest),\n",
    "            naive_bayes.predict(x_test),\n",
    "            logistica.predict(x_test),\n",
    "            random_forest.predict(x_test),\n",
    "            y_test]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d172b811",
   "metadata": {},
   "outputs": [],
   "source": [
    "resultados_naive_bayes_norm, resultados_logistica_norm, resultados_forest_norm, previsoes_naive, previsoes_log, previsoes_forest, y_test = normalize_and_train(x, y);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60cf84c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(20,5))\n",
    "plt.subplot(1, 3, 1)\n",
    "plt.title(\"Naïve Bayes\")\n",
    "plt.subplot(sns.heatmap(confusion_matrix(previsoes_naive, y_test), annot=True))\n",
    "plt.subplot(1, 3, 2)\n",
    "plt.title(\"Regressão Logística\")\n",
    "plt.subplot(sns.heatmap(confusion_matrix(previsoes_log, y_test), annot=True))\n",
    "plt.subplot(1, 3, 3)\n",
    "plt.title(\"Árvore de Decisão\")\n",
    "plt.subplot(sns.heatmap(confusion_matrix(previsoes_forest, y_test), annot=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b932f5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Média: Naïve Bayes {:.5}, Regressão Log. {:.5}, Árvore de decisão {:.5}\".format(resultados_naive_bayes_norm.mean(), resultados_logistica_norm.mean(), resultados_forest_norm.mean()))\n",
    "print(\"Desvio Padrão: Naïve Bayes {:.5}, Regressão Log. {:.5}, Árvore de decisão {:.5}\".format(np.std(resultados_naive_bayes_norm), np.std(resultados_logistica_norm), np.std(resultados_forest_norm)))\n",
    "print(\"Coeficiente de variação: Naïve Bayes {:.5}, Regressão Log. {:.5}, Árvore de decisão {:.5}\".format(stats.variation(resultados_naive_bayes_norm), stats.variation(resultados_logistica_norm), stats.variation(resultados_forest_norm)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d7825cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(20,5))\n",
    "plt.subplot(1, 3, 1)\n",
    "plt.title(\"Naïve Bayes\")\n",
    "plt.subplot(sns.distplot(resultados_naive_bayes_norm, color=\"red\", label=\"Naïve Bayes\", hist=False, kde=True))\n",
    "plt.legend();\n",
    "\n",
    "plt.subplot(1, 3, 2)\n",
    "plt.title(\"Regressão Logística\")\n",
    "plt.subplot(sns.distplot(resultados_logistica_norm, color=\"green\", label=\"Reg. Logística\", hist=False, kde=True))\n",
    "plt.legend();\n",
    "\n",
    "plt.subplot(1, 3, 3)\n",
    "plt.title(\"Árvore de Decisão\")\n",
    "plt.subplot(sns.distplot(resultados_forest_norm, color=\"blue\", label=\"Random Forest\", hist=False, kde=True))\n",
    "plt.legend();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9699918",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
