{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Pichau\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:526: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "C:\\Users\\Pichau\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:527: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "C:\\Users\\Pichau\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:528: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "C:\\Users\\Pichau\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:529: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "C:\\Users\\Pichau\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:530: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "C:\\Users\\Pichau\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:535: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os, shutil, json\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "from numpy import argmax\n",
    "from PIL import Image\n",
    "from pathlib import Path\n",
    "import keras\n",
    "from keras import backend as K\n",
    "from keras.utils import np_utils\n",
    "from keras.regularizers import l2\n",
    "from keras.models import Sequential\n",
    "from keras.optimizers import RMSprop, Adam, SGD\n",
    "from keras.preprocessing import image\n",
    "from keras.engine.topology import Layer\n",
    "from keras.utils.np_utils import to_categorical\n",
    "from keras.initializers import truncated_normal\n",
    "from keras.losses import categorical_crossentropy, binary_crossentropy, mean_squared_error, mean_squared_logarithmic_error\n",
    "from keras.callbacks import ModelCheckpoint, EarlyStopping\n",
    "from keras_contrib.layers.advanced_activations.swish import Swish\n",
    "from keras.preprocessing.image import img_to_array, ImageDataGenerator\n",
    "from keras import layers, models, regularizers, backend, utils\n",
    "from keras.layers import Activation, BatchNormalization, Conv2D, Conv2DTranspose, Dense, Dropout, Flatten, initializers, InputSpec, Input, LeakyReLU, MaxPooling2D, Reshape\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "abs_path = r'%s' % os.getcwd().replace('\\\\','/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>path</th>\n",
       "      <th>width</th>\n",
       "      <th>height</th>\n",
       "      <th>size</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0_2000.jpg</td>\n",
       "      <td>63</td>\n",
       "      <td>63</td>\n",
       "      <td>63 63</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>10000_2004.jpg</td>\n",
       "      <td>62</td>\n",
       "      <td>62</td>\n",
       "      <td>62 62</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>10001_2004.jpg</td>\n",
       "      <td>79</td>\n",
       "      <td>79</td>\n",
       "      <td>79 79</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>10002_2004.jpg</td>\n",
       "      <td>51</td>\n",
       "      <td>51</td>\n",
       "      <td>51 51</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>10003_2004.jpg</td>\n",
       "      <td>77</td>\n",
       "      <td>77</td>\n",
       "      <td>77 77</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             path  width  height   size\n",
       "0      0_2000.jpg     63      63  63 63\n",
       "1  10000_2004.jpg     62      62  62 62\n",
       "2  10001_2004.jpg     79      79  79 79\n",
       "3  10002_2004.jpg     51      51  51 51\n",
       "4  10003_2004.jpg     77      77  77 77"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Imagens_DataFrame = pd.read_csv(\"./1_imagens_Mckinsey666.csv\") \n",
    "Imagens_DataFrame.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>path</th>\n",
       "      <th>width</th>\n",
       "      <th>height</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>size</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>90 90</th>\n",
       "      <td>1516</td>\n",
       "      <td>1516</td>\n",
       "      <td>1516</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95 95</th>\n",
       "      <td>1530</td>\n",
       "      <td>1530</td>\n",
       "      <td>1530</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>94 94</th>\n",
       "      <td>1534</td>\n",
       "      <td>1534</td>\n",
       "      <td>1534</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96 96</th>\n",
       "      <td>1556</td>\n",
       "      <td>1556</td>\n",
       "      <td>1556</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>92 92</th>\n",
       "      <td>1636</td>\n",
       "      <td>1636</td>\n",
       "      <td>1636</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       path  width  height\n",
       "size                      \n",
       "90 90  1516   1516    1516\n",
       "95 95  1530   1530    1530\n",
       "94 94  1534   1534    1534\n",
       "96 96  1556   1556    1556\n",
       "92 92  1636   1636    1636"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Imagens_DataFrame.groupby('size').count().sort_values('path').tail()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Modelo 32x32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class rede_32:\n",
    "    def __init__(self, batch_size = 20):\n",
    "        self.latent_dim = 32\n",
    "        self.height = 32\n",
    "        self.width = 32\n",
    "        self.channels = 3\n",
    "        self.iterations = 10000\n",
    "        self.batch_size = batch_size\n",
    "        self.NPZ_file_path = os.path.join(abs_path, \"2_imagens_Mckinsey666_\"+str(self.height)+\"_\"+str(self.height)+\".npz\").replace('\\\\','/')\n",
    "        self.create_numpy_file()\n",
    "        \n",
    "        images_path = os.path.join(abs_path,'2_Generated_Images_' + str(self.height) + '_' + str(self.height)).replace('\\\\','/')\n",
    "        if not os.path.exists(images_path):\n",
    "            os.mkdir(images_path)\n",
    "        self.save_dir = images_path\n",
    "        \n",
    "    def create_numpy_file(self):\n",
    "        imagens_x = []\n",
    "        if not os.path.exists(self.NPZ_file_path):\n",
    "            Imagens_DataFrame = pd.read_csv(\"./1_imagens_Mckinsey666.csv\")\n",
    "            for index, row in Imagens_DataFrame.iterrows():\n",
    "                    image_path = os.path.join(abs_path, '1_Mckinsey666', row['path']).replace('\\\\','/')\n",
    "                    image = Image.open(image_path)\n",
    "                    newsize = (32, 32) \n",
    "                    image = image.resize(newsize) \n",
    "                    image_numpy = np.asarray(image)\n",
    "                    imagens_x.append(image_numpy)\n",
    "\n",
    "            imagens_x = np.asarray(imagens_x, dtype=np.float32)\n",
    "            np.savez(self.NPZ_file_path, x=imagens_x)\n",
    "    \n",
    "    def get_images_as_nparray(self):\n",
    "        with np.load(self.NPZ_file_path) as data:\n",
    "            imagens_x = data['x']\n",
    "        x_train = imagens_x.reshape(\n",
    "                (imagens_x.shape[0],) + \n",
    "                (self.height, self.width, self.channels)).astype('float32') / 255.\n",
    "        return x_train\n",
    "        \n",
    "    def create_generator(self):\n",
    "        generator_input = keras.Input(shape=(self.latent_dim,))\n",
    "\n",
    "        #Transforms the input into a 16 × 16 128-channel feature map\n",
    "        x = Dense(128 * 16 * 16)(generator_input)\n",
    "        x = LeakyReLU()(x)\n",
    "        x = Reshape((16, 16, 128))(x)\n",
    "\n",
    "        x = Conv2D(256, 5, padding='same')(x)\n",
    "        x = LeakyReLU()(x)\n",
    "\n",
    "        #Upsamples to 32 × 32\n",
    "        x = Conv2DTranspose(256, 4, strides=2, padding='same')(x)\n",
    "        x = LeakyReLU()(x)\n",
    "        x = Conv2D(256, 5, padding='same')(x)\n",
    "        x = LeakyReLU()(x)\n",
    "        x = Conv2D(256, 5, padding='same')(x)\n",
    "        x = LeakyReLU()(x)\n",
    "\n",
    "        #Produces a 32 × 32 1-channel feature map (shape of a CIFAR10 image)\n",
    "        x = Conv2D(self.channels, 7, activation='tanh', padding='same')(x)\n",
    "        #Instantiates the generator model, which maps the input of shape (latent_dim,) into an image of shape (32, 32, 3)\n",
    "        generator = keras.models.Model(generator_input, x)\n",
    "        #generator.summary()\n",
    "        return generator\n",
    "    \n",
    "    def create_discriminator(self):\n",
    "        discriminator_input = Input(shape=(self.height, self.width, self.channels))\n",
    "        x = Conv2D(128, 3)(discriminator_input)\n",
    "        x = LeakyReLU()(x)\n",
    "        x = Conv2D(128, 4, strides=2)(x)\n",
    "        x = LeakyReLU()(x)\n",
    "        x = Conv2D(128, 4, strides=2)(x)\n",
    "        x = LeakyReLU()(x)\n",
    "        x = Conv2D(128, 4, strides=2)(x)\n",
    "        x = LeakyReLU()(x)\n",
    "        x = Flatten()(x)\n",
    "        #One dropout layer: an important trick!\n",
    "        x = Dropout(0.4)(x)\n",
    "        #Classification layer\n",
    "        x = Dense(1, activation='sigmoid')(x)\n",
    "        #Instantiates the discriminator model, which turns a (32, 32, 3) input into a\n",
    "        #binary classifi-cation decision (fake/real)\n",
    "        discriminator = keras.models.Model(discriminator_input, x)\n",
    "        #discriminator.summary()\n",
    "\n",
    "        discriminator_optimizer = keras.optimizers.RMSprop(\n",
    "                lr=0.0008,\n",
    "                clipvalue=1.0, #Uses gradient clipping (by value) in the optimizer\n",
    "                decay=1e-8) #To stabilize training, uses learning-rate decay\n",
    "        discriminator.compile(optimizer=discriminator_optimizer, \n",
    "                              loss='binary_crossentropy')\n",
    "        \n",
    "        return discriminator\n",
    "    \n",
    "    def create_adversarial_net(self):\n",
    "        #Sets discriminator weights to non-trainable (this will only apply to the gan model) \n",
    "        discriminator = self.create_discriminator()\n",
    "        discriminator.trainable = False\n",
    "        gan_input = keras.Input(shape=(self.latent_dim,))\n",
    "        generator = self.create_generator()\n",
    "        gan_output = discriminator(generator(gan_input))\n",
    "        gan = keras.models.Model(gan_input, gan_output)\n",
    "        gan_optimizer = keras.optimizers.RMSprop(lr=0.0004, clipvalue=1.0, decay=1e-8)\n",
    "        gan.compile(optimizer=gan_optimizer, loss='binary_crossentropy')\n",
    "        \n",
    "        return [generator, discriminator, gan]\n",
    "    \n",
    "    def build_network(self):\n",
    "        start = 0\n",
    "        generator, discriminator, gan = self.create_adversarial_net()\n",
    "        x_train = self.get_images_as_nparray()\n",
    "        \n",
    "        for step in range(self.iterations):\n",
    "            #Samples random points in the latent space\n",
    "            random_latent_vectors = np.random.normal(size=(self.batch_size,self.latent_dim))\n",
    "            #Decodes them to fake images\n",
    "            generated_images = generator.predict(random_latent_vectors)\n",
    "            #Combines them with real images\n",
    "            stop = start + self.batch_size\n",
    "            real_images = x_train[start: stop]\n",
    "            combined_images = np.concatenate([generated_images, real_images])\n",
    "            #Assembles labels, discriminating real from fake images\n",
    "            labels = np.concatenate([np.ones((self.batch_size, 1)),\n",
    "                                     np.zeros((self.batch_size, 1))])\n",
    "            #Adds random noise to the labels—an important trick!\n",
    "            labels += 0.05 * np.random.random(labels.shape)\n",
    "            #Trains the discriminator\n",
    "            d_loss = discriminator.train_on_batch(combined_images, labels)\n",
    "            #Samples random points in the latent space\n",
    "            random_latent_vectors = np.random.normal(size=(self.batch_size,\n",
    "                                                           self.latent_dim))\n",
    "            #Assembles labels that say “these are all real images” (it’s a lie!)\n",
    "            misleading_targets = np.zeros((self.batch_size, 1))\n",
    "            #Trains the generator (via the gan model, where the discriminator weights are frozen)\n",
    "            a_loss = gan.train_on_batch(random_latent_vectors,\n",
    "                                        misleading_targets)\n",
    "            start += self.batch_size\n",
    "            if start > len(x_train) - self.batch_size:\n",
    "                start = 0\n",
    "            #Occasionally saves and plots (every 100 steps)\n",
    "            if step % 100 == 0:\n",
    "                #Saves model weights\n",
    "                gan.save_weights(\"2_GAN_model_gan_\"+str(self.height)+\"_\"+str(self.height)+\".h5\")\n",
    "                #Prints metrics\n",
    "                print('{} - discriminator loss: {} - adversarial loss: {}'.format(step, d_loss, a_loss))\n",
    "                #Saves one generated image\n",
    "                img = image.array_to_img(generated_images[0] * 255., scale=False)\n",
    "                img.save(os.path.join(self.save_dir,'2_GAN_' + str(step) + '_generated_anime.png'))\n",
    "                #Saves one real image for comparison\n",
    "                img = image.array_to_img(real_images[0] * 255., scale=False)\n",
    "                img.save(os.path.join(self.save_dir,'2_GAN_' + str(step) + '_real_anime.png'))\n",
    "            if step == self.iterations-1:\n",
    "                valores_1 = discriminator.evaluate(x_train, np.zeros((int(x_train.shape[0]), 1)))\n",
    "                valores_0 = discriminator.evaluate(generated_images, np.ones((self.batch_size, 1)))\n",
    "                print('Imagens reais - test loss, test acc:', valores_1)\n",
    "                print('Imagens geradas - test loss, test acc:', valores_0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "rede_32 = rede_32(128)\n",
    "rede_32.build_network()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
