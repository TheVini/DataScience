{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n",
      "C:\\Users\\Pichau\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:526: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "C:\\Users\\Pichau\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:527: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "C:\\Users\\Pichau\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:528: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "C:\\Users\\Pichau\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:529: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "C:\\Users\\Pichau\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:530: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "C:\\Users\\Pichau\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:535: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os, shutil, json\n",
    "import matplotlib.pyplot as plt\n",
    "import keras\n",
    "from PIL import Image\n",
    "from pathlib import Path\n",
    "from statistics import mean \n",
    "from keras import backend as K\n",
    "from keras.models import Sequential, load_model\n",
    "from keras.optimizers import RMSprop, Adam, SGD\n",
    "from keras.preprocessing import image\n",
    "from keras.utils.np_utils import to_categorical\n",
    "from keras.losses import categorical_crossentropy, binary_crossentropy, mean_squared_error, mean_squared_logarithmic_error\n",
    "from keras.preprocessing.image import img_to_array, ImageDataGenerator\n",
    "from keras import layers, models, regularizers, backend, utils\n",
    "from keras.layers import Activation, BatchNormalization, Conv2D, Conv2DTranspose, Dense, Dropout, Flatten, initializers, InputSpec, Input, LeakyReLU, MaxPooling2D, Reshape\n",
    "\n",
    "abs_path = r'%s' % os.getcwd().replace('\\\\','/')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Modelo Genérico"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class rede:\n",
    "    def __init__(self, batch_size = 20, images_size = 64):\n",
    "        self.generator_input = 100\n",
    "        self.latent_dim = 32\n",
    "        self.height = images_size\n",
    "        self.width = images_size\n",
    "        self.channels = 3\n",
    "        self.iterations = 20000\n",
    "        self.batch_size = batch_size\n",
    "        self.NPZ_file_path = os.path.join(abs_path, \"2_imagens_Mckinsey666_\"+str(self.height)+\"_\"+str(self.height)+\".npz\").replace('\\\\','/')\n",
    "        self.create_numpy_file()\n",
    "        self.my_ReduceLROnPlateau_losses = []\n",
    "        self.my_ReduceLROnPlateau_sentinela = 0\n",
    "        self.generator = []\n",
    "        self.discriminator = []\n",
    "        self.gan = []\n",
    "        \n",
    "        images_path = os.path.join(abs_path,'2_Generated_Images_' + str(self.height) + '_' + str(self.height) + '_Presentation').replace('\\\\','/')\n",
    "        if not os.path.exists(images_path):\n",
    "            os.mkdir(images_path)\n",
    "        self.save_dir = images_path\n",
    "        \n",
    "    def create_numpy_file(self):\n",
    "        imagens_x = []\n",
    "        if not os.path.exists(self.NPZ_file_path):\n",
    "            Imagens_DataFrame = pd.read_csv(\"./1_imagens_Mckinsey666.csv\")\n",
    "            for index, row in Imagens_DataFrame.iterrows():\n",
    "                    image_path = os.path.join(abs_path, '1_Mckinsey666', row['path']).replace('\\\\','/')\n",
    "                    image = Image.open(image_path)\n",
    "                    newsize = (self.height, self.width)\n",
    "                    image = image.resize(newsize, Image.LANCZOS) \n",
    "                    image_numpy = np.asarray(image)\n",
    "                    imagens_x.append(image_numpy)\n",
    "                    #imagens_x.append(np.rot90(image_numpy))\n",
    "                    #imagens_x.append(np.rot90(image_numpy, 3))\n",
    "\n",
    "            imagens_x = np.asarray(imagens_x, dtype=np.float32)\n",
    "            np.savez(self.NPZ_file_path, x=imagens_x)\n",
    "    \n",
    "    def get_images_as_nparray(self):\n",
    "        with np.load(self.NPZ_file_path) as data:\n",
    "            imagens_x = data['x']\n",
    "        #x_train = imagens_x.reshape((imagens_x.shape[0],) + (self.height, self.width, self.channels)).astype('float32') / 255.\n",
    "        x_train = (imagens_x.reshape((imagens_x.shape[0],) + (self.height, self.width, self.channels)).astype('float32') - 127.5 ) / 127.5\n",
    "        #x_train = (imagens_x.reshape((imagens_x.shape[0],) + (self.height, self.width, self.channels)).astype('float32') / 127.5 ) - 0.5\n",
    "        return x_train\n",
    "        \n",
    "    def create_generator(self):\n",
    "        generator_input = keras.Input(shape=(self.generator_input,))\n",
    "        \n",
    "        x = Dense(128 * int(self.height/2) * int(self.width/2))(generator_input)\n",
    "        x = LeakyReLU()(x)\n",
    "        x = Reshape((int(self.height/2), int(self.width/2), 128))(x)\n",
    "\n",
    "        x = Conv2D(256, 5, padding='same')(x)\n",
    "        x = LeakyReLU()(x)\n",
    "\n",
    "        x = Conv2DTranspose(256, 4, strides=2, padding='same')(x)\n",
    "        x = LeakyReLU()(x)\n",
    "        x = Conv2D(256, 5, padding='same')(x)\n",
    "        x = LeakyReLU()(x)\n",
    "        x = Conv2D(256, 5, padding='same')(x)\n",
    "        x = LeakyReLU()(x)\n",
    "        #Produces a 32 × 32 1-channel feature map (shape of a CIFAR10 image)\n",
    "        x = Conv2D(self.channels, 7, activation='tanh', padding='same')(x)\n",
    "        #Instantiates the generator model, which maps the input of shape (latent_dim,) into an image of shape (32, 32, 3)\n",
    "        model = keras.models.Model(generator_input, x)\n",
    "        \n",
    "        return model\n",
    "        \n",
    "    \n",
    "    def create_discriminator(self):\n",
    "        discriminator_input = Input(shape=(self.height, self.width, self.channels))\n",
    "        x = Conv2D(128, 3)(discriminator_input)\n",
    "        x = LeakyReLU()(x)\n",
    "\n",
    "        x = Conv2D(128, 4, strides=2)(x)\n",
    "        x = LeakyReLU()(x)\n",
    "\n",
    "        x = Conv2D(128, 4, strides=2)(x)\n",
    "        x = LeakyReLU()(x)\n",
    "\n",
    "        x = Conv2D(128, 4, strides=2)(x)\n",
    "        x = LeakyReLU()(x)\n",
    "\n",
    "        x = Flatten()(x)\n",
    "        x = Dropout(0.4)(x)\n",
    "        x = Dense(1, activation='sigmoid')(x)\n",
    "        model = keras.models.Model(discriminator_input, x)\n",
    "\n",
    "        discriminator_optimizer = keras.optimizers.RMSprop(\n",
    "                lr=0.0008,\n",
    "                clipvalue=1.0, #Uses gradient clipping (by value) in the optimizer\n",
    "                decay=1e-8) #To stabilize training, uses learning-rate decay\n",
    "        model.compile(optimizer=Adam(0.0001, beta_1=0.5, beta_2=0.9), loss='binary_crossentropy')\n",
    "        #model.compile(optimizer=discriminator_optimizer, loss='binary_crossentropy')\n",
    "        return model\n",
    "    \n",
    "    def create_adversarial_net(self):\n",
    "        #Sets discriminator weights to non-trainable (this will only apply to the gan model) \n",
    "        self.discriminator = self.create_discriminator()\n",
    "        self.generator = self.create_generator()\n",
    "        \n",
    "        self.discriminator.trainable = False\n",
    "        gan_input = keras.Input(shape=(self.generator_input,))\n",
    "        gan_output = self.discriminator(self.generator(gan_input))\n",
    "        self.gan = keras.models.Model(gan_input, gan_output)\n",
    "        gan_optimizer = RMSprop(lr=0.0004, clipvalue=1.0, decay=1e-8)\n",
    "        #self.gan.compile(optimizer=gan_optimizer, loss=\"binary_crossentropy\")\n",
    "        self.gan.compile(optimizer=Adam(0.0001, beta_1=0.5, beta_2=0.9), loss='binary_crossentropy')\n",
    "\n",
    "    def my_ReduceLROnPlateau_loss(self, new_loss, step_of_iterations, factor = 0.5, patience = 10, epsilon = 1e-04, cooldown = 0, min_lr=0):\n",
    "        #Se a lista estiver cheia, remove o primeiro elemento\n",
    "        if len(self.my_ReduceLROnPlateau_losses) == patience:\n",
    "            self.my_ReduceLROnPlateau_losses.pop(0)\n",
    "            \n",
    "        #Se for lista, existirá dois valores dentro, então  obtém só o primeiro\n",
    "        if type(new_loss) is list:\n",
    "            new_loss = new_loss[0]\n",
    "        self.my_ReduceLROnPlateau_losses.append(new_loss)\n",
    "        \n",
    "        valor_antigo = float(K.get_value(self.discriminator.optimizer.lr))\n",
    "        #Checa se a lista de pesos está cheia, a quantas iterações foi a última alteração\n",
    "        if len(self.my_ReduceLROnPlateau_losses) == 10 and (step_of_iterations - self.my_ReduceLROnPlateau_sentinela) > cooldown and valor_antigo > min_lr:\n",
    "            valor_min = mean(self.my_ReduceLROnPlateau_losses) - epsilon\n",
    "            valor_max = mean(self.my_ReduceLROnPlateau_losses) + epsilon\n",
    "            #verifica se houve alterações nos \"Losses\" nas últimas \"patience\" épocas\n",
    "            validacao = [ (loss < valor_min or loss > valor_max) for loss in self.my_ReduceLROnPlateau_losses]\n",
    "            if False in validacao: \n",
    "                valor_novo = valor_antigo * factor\n",
    "                K.set_value(self.discriminator.optimizer.lr, valor_novo)\n",
    "                print(\"[CALLBACK] Learning Rate atualizado na época {} de {} para {}\".format(step_of_iterations, valor_antigo, valor_novo))\n",
    "                #Se houver uma alteração, esprar \"cooldown\" rodadas para fazer uma nova alteração\n",
    "                self.my_ReduceLROnPlateau_sentinela = step_of_iterations\n",
    "                \n",
    "    def wasserstein_loss(self, y_true, y_pred):\n",
    "        return K.mean(y_true * y_pred)\n",
    "    \n",
    "    def get_randomly_batch_images(self, x_train):\n",
    "        pacotes = x_train.shape[0] // self.batch_size\n",
    "        inicio_batch = int(pacotes * np.random.randint(self.batch_size + 1, size=1))\n",
    "        final_batch = int(inicio_batch + self.batch_size)\n",
    "        if final_batch > x_train.shape[0]:\n",
    "            diferenca = final_batch - x_train.shape[0]\n",
    "            real_images = np.concatenate((x_train[inicio_batch:], x_train[:diferenca]), axis=0)\n",
    "            #print(\"{} {} {} {} {} {} {}\".format(inicio_batch, final_batch, x_train.shape[0], x_train[inicio_batch:].shape, x_train[:diferenca].shape, diferenca, real_images.shape))\n",
    "        else:\n",
    "            real_images = x_train[inicio_batch:final_batch]\n",
    "        assert real_images.shape == (self.batch_size, self.height, self.height, self.channels)\n",
    "        return real_images\n",
    "    \n",
    "    def build_network(self):\n",
    "        start = 0\n",
    "        self.create_adversarial_net()\n",
    "        x_train = self.get_images_as_nparray()\n",
    "        \n",
    "        for step in range(self.iterations):            \n",
    "            #TREINAR O DISCRIMINATOR\n",
    "            random_latent_vectors = np.random.normal(size=(self.batch_size, self.generator_input))\n",
    "            generated_images = self.generator.predict(random_latent_vectors)\n",
    "\n",
    "            stop = start + self.batch_size\n",
    "            real_images = x_train[start: stop]\n",
    "\n",
    "            #real_images = self.get_randomly_batch_images(x_train)\n",
    "            combined_images = np.concatenate([generated_images, real_images])\n",
    "            labels = np.concatenate([np.zeros((self.batch_size, 1), dtype=np.float32), np.ones((self.batch_size, 1), dtype=np.float32)])\n",
    "            #labels = np.concatenate([-np.ones((self.batch_size, 1)), np.ones((self.batch_size, 1))])\n",
    "            #Adds random noise to the labels—an important trick!\n",
    "            labels += 0.05 * np.random.random(labels.shape)\n",
    "            d_loss = self.discriminator.train_on_batch(combined_images, labels)\n",
    "            \n",
    "            #TREINAR O GENERATOR\n",
    "            random_latent_vectors = np.random.normal(size=(self.batch_size, self.generator_input))\n",
    "            misleading_targets = np.ones((self.batch_size, 1), dtype=np.float32)\n",
    "            a_loss = self.gan.train_on_batch(random_latent_vectors, misleading_targets)\n",
    "            \n",
    "            #CALLBACKS\n",
    "            self.my_ReduceLROnPlateau_loss(d_loss, step, patience=15, cooldown = 15)\n",
    "\n",
    "            start += self.batch_size\n",
    "            if start > len(x_train) - self.batch_size:\n",
    "                start = 0\n",
    "\n",
    "            if step % 25== 0 or step == self.iterations-1:\n",
    "                self.generator.save(\"2_Generator_model_gan_\"+str(self.height)+\"_\"+str(self.height)+\"_Presentation.h5\")\n",
    "                print('{} - discriminator loss: {} - adversarial loss: {}'.format(step, d_loss, a_loss))\n",
    "                step_string = \"{:06d}\".format(step)\n",
    "                new_dir = os.path.join(self.save_dir,'Epoca_'+step_string).replace('\\\\','/')\n",
    "                if not os.path.exists(new_dir):\n",
    "                    os.mkdir(new_dir)\n",
    "                for image_number in range(self.batch_size):\n",
    "                    img = image.array_to_img(np.squeeze(np.round((generated_images[image_number] * 127.5) + 127.5).astype(np.uint8)), scale=False)\n",
    "                    img.save(os.path.join(new_dir,'2_GAN_' + str(image_number) + '_generated_anime.png'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\Pichau\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n",
      "WARNING:tensorflow:From C:\\Users\\Pichau\\Anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:3445: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n",
      "WARNING:tensorflow:From C:\\Users\\Pichau\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\ops\\math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Pichau\\Anaconda3\\lib\\site-packages\\keras\\engine\\training.py:490: UserWarning: Discrepancy between trainable weights and collected trainable weights, did you set `model.trainable` without calling `model.compile` after ?\n",
      "  'Discrepancy between trainable weights and collected trainable'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 - discriminator loss: 0.7068132758140564 - adversarial loss: 0.6931306719779968\n",
      "25 - discriminator loss: 0.2642636299133301 - adversarial loss: 0.7125013470649719\n",
      "50 - discriminator loss: 1.1692270040512085 - adversarial loss: 0.29036465287208557\n",
      "75 - discriminator loss: 0.6987295150756836 - adversarial loss: 0.7806828022003174\n",
      "100 - discriminator loss: 0.718989372253418 - adversarial loss: 0.8321815729141235\n",
      "125 - discriminator loss: 0.6619747877120972 - adversarial loss: 0.6345105171203613\n",
      "150 - discriminator loss: 0.5410618782043457 - adversarial loss: 1.4828530550003052\n",
      "175 - discriminator loss: 0.7011469006538391 - adversarial loss: 0.9433771371841431\n",
      "200 - discriminator loss: 0.550859808921814 - adversarial loss: 0.9601483345031738\n",
      "225 - discriminator loss: 0.5943605899810791 - adversarial loss: 1.1185613870620728\n",
      "250 - discriminator loss: 0.5534605383872986 - adversarial loss: 1.2851629257202148\n",
      "275 - discriminator loss: 0.6759033799171448 - adversarial loss: 0.8109022378921509\n",
      "300 - discriminator loss: 0.333340048789978 - adversarial loss: 1.7499574422836304\n",
      "325 - discriminator loss: 0.9515236020088196 - adversarial loss: 1.570420503616333\n",
      "350 - discriminator loss: 0.5472602248191833 - adversarial loss: 0.9382975101470947\n",
      "375 - discriminator loss: 0.5275833606719971 - adversarial loss: 1.3089500665664673\n",
      "400 - discriminator loss: 0.6255677938461304 - adversarial loss: 0.8824257850646973\n",
      "425 - discriminator loss: 0.7545315027236938 - adversarial loss: 0.8646724224090576\n",
      "450 - discriminator loss: 0.692414402961731 - adversarial loss: 0.8823041319847107\n",
      "475 - discriminator loss: 0.6502935886383057 - adversarial loss: 1.003810167312622\n",
      "500 - discriminator loss: 0.6994715332984924 - adversarial loss: 1.006056547164917\n",
      "525 - discriminator loss: 0.6500518321990967 - adversarial loss: 0.7713805437088013\n",
      "550 - discriminator loss: 0.7830822467803955 - adversarial loss: 0.9603536128997803\n",
      "575 - discriminator loss: 0.602158784866333 - adversarial loss: 0.9343599081039429\n",
      "600 - discriminator loss: 0.7687278389930725 - adversarial loss: 0.9219937324523926\n",
      "625 - discriminator loss: 0.6625939607620239 - adversarial loss: 0.8287158608436584\n",
      "650 - discriminator loss: 0.6650412082672119 - adversarial loss: 0.8702000975608826\n",
      "675 - discriminator loss: 0.6789091229438782 - adversarial loss: 0.8014417886734009\n",
      "700 - discriminator loss: 0.6384621858596802 - adversarial loss: 0.8518311977386475\n",
      "725 - discriminator loss: 0.7431166172027588 - adversarial loss: 0.7697306871414185\n",
      "750 - discriminator loss: 0.6895520091056824 - adversarial loss: 0.8660509586334229\n",
      "775 - discriminator loss: 0.7318267822265625 - adversarial loss: 0.7937522530555725\n",
      "800 - discriminator loss: 0.688775897026062 - adversarial loss: 0.6437690854072571\n",
      "825 - discriminator loss: 0.7023040056228638 - adversarial loss: 0.6649622917175293\n",
      "850 - discriminator loss: 0.6749553084373474 - adversarial loss: 0.8104646801948547\n",
      "875 - discriminator loss: 0.6651362776756287 - adversarial loss: 0.7399660348892212\n",
      "900 - discriminator loss: 0.6910772323608398 - adversarial loss: 0.7568318843841553\n",
      "925 - discriminator loss: 0.6967183947563171 - adversarial loss: 0.6902080774307251\n",
      "950 - discriminator loss: 0.687496542930603 - adversarial loss: 0.6810111999511719\n",
      "975 - discriminator loss: 0.7070432901382446 - adversarial loss: 0.6894036531448364\n",
      "1000 - discriminator loss: 0.7282540798187256 - adversarial loss: 0.6204912662506104\n",
      "1025 - discriminator loss: 0.7138484716415405 - adversarial loss: 0.6377736330032349\n",
      "1050 - discriminator loss: 0.7097625136375427 - adversarial loss: 0.6414594650268555\n",
      "1075 - discriminator loss: 0.7104693651199341 - adversarial loss: 0.6102755069732666\n",
      "1100 - discriminator loss: 0.7013163566589355 - adversarial loss: 0.6046652793884277\n",
      "1125 - discriminator loss: 0.6894162893295288 - adversarial loss: 0.683782696723938\n",
      "1150 - discriminator loss: 0.7006828188896179 - adversarial loss: 0.6872389316558838\n",
      "1175 - discriminator loss: 0.708908200263977 - adversarial loss: 0.685233473777771\n",
      "1200 - discriminator loss: 0.6979678273200989 - adversarial loss: 0.6611613035202026\n",
      "1225 - discriminator loss: 0.7016792297363281 - adversarial loss: 0.6471654176712036\n",
      "1250 - discriminator loss: 0.7175527215003967 - adversarial loss: 0.6892019510269165\n",
      "1275 - discriminator loss: 0.6867181062698364 - adversarial loss: 0.6705313920974731\n",
      "1300 - discriminator loss: 0.6975502371788025 - adversarial loss: 0.6783281564712524\n",
      "1325 - discriminator loss: 0.7034780979156494 - adversarial loss: 0.6079605221748352\n",
      "1350 - discriminator loss: 0.707092821598053 - adversarial loss: 0.6688788533210754\n",
      "1375 - discriminator loss: 0.706009030342102 - adversarial loss: 0.6501219272613525\n",
      "1400 - discriminator loss: 0.6943782567977905 - adversarial loss: 0.673120379447937\n",
      "1425 - discriminator loss: 0.6942905187606812 - adversarial loss: 0.6828349828720093\n",
      "1450 - discriminator loss: 0.7027323246002197 - adversarial loss: 0.6632944941520691\n",
      "1475 - discriminator loss: 0.6969051957130432 - adversarial loss: 0.6427773237228394\n",
      "1500 - discriminator loss: 0.697968602180481 - adversarial loss: 0.6704949736595154\n",
      "1525 - discriminator loss: 0.7011638879776001 - adversarial loss: 0.6288807392120361\n",
      "1550 - discriminator loss: 0.6942881941795349 - adversarial loss: 0.6484928131103516\n",
      "1575 - discriminator loss: 0.6912364959716797 - adversarial loss: 0.6742013692855835\n",
      "1600 - discriminator loss: 0.6989519596099854 - adversarial loss: 0.6805228590965271\n",
      "1625 - discriminator loss: 0.6940715312957764 - adversarial loss: 0.6552069783210754\n",
      "1650 - discriminator loss: 0.6997340321540833 - adversarial loss: 0.6563845872879028\n",
      "1675 - discriminator loss: 0.6985077261924744 - adversarial loss: 0.67351233959198\n",
      "1700 - discriminator loss: 0.6936118602752686 - adversarial loss: 0.65948086977005\n",
      "1725 - discriminator loss: 0.691623866558075 - adversarial loss: 0.666465699672699\n",
      "1750 - discriminator loss: 0.6957226991653442 - adversarial loss: 0.6523467898368835\n",
      "1775 - discriminator loss: 0.6948122978210449 - adversarial loss: 0.6580232381820679\n",
      "1800 - discriminator loss: 0.6999621987342834 - adversarial loss: 0.6756613254547119\n",
      "1825 - discriminator loss: 0.6917895078659058 - adversarial loss: 0.661506175994873\n",
      "1850 - discriminator loss: 0.6970375180244446 - adversarial loss: 0.6669649481773376\n",
      "1875 - discriminator loss: 0.6951284408569336 - adversarial loss: 0.6466891765594482\n",
      "1900 - discriminator loss: 0.6934395432472229 - adversarial loss: 0.6610078811645508\n",
      "1925 - discriminator loss: 0.6820694208145142 - adversarial loss: 0.6114927530288696\n",
      "1950 - discriminator loss: 0.6871742010116577 - adversarial loss: 0.6666207313537598\n",
      "1975 - discriminator loss: 0.6853756904602051 - adversarial loss: 0.6554098129272461\n",
      "2000 - discriminator loss: 0.7008711099624634 - adversarial loss: 0.6007617712020874\n",
      "2025 - discriminator loss: 0.6886814832687378 - adversarial loss: 0.666935920715332\n",
      "2050 - discriminator loss: 0.7004925608634949 - adversarial loss: 0.6540281772613525\n",
      "2075 - discriminator loss: 0.7037521600723267 - adversarial loss: 0.628356397151947\n",
      "2100 - discriminator loss: 0.6933377981185913 - adversarial loss: 0.676783561706543\n",
      "2125 - discriminator loss: 0.6917885541915894 - adversarial loss: 0.6321929693222046\n",
      "2150 - discriminator loss: 0.6966188549995422 - adversarial loss: 0.663931131362915\n",
      "2175 - discriminator loss: 0.6940557956695557 - adversarial loss: 0.6597466468811035\n",
      "2200 - discriminator loss: 0.6936200261116028 - adversarial loss: 0.6235041618347168\n",
      "2225 - discriminator loss: 0.6921536326408386 - adversarial loss: 0.6290265321731567\n",
      "2250 - discriminator loss: 0.6949144005775452 - adversarial loss: 0.6467249989509583\n",
      "2275 - discriminator loss: 0.7116057872772217 - adversarial loss: 0.611571192741394\n",
      "2300 - discriminator loss: 0.6929157972335815 - adversarial loss: 0.6426277160644531\n",
      "2325 - discriminator loss: 0.7159138321876526 - adversarial loss: 0.6403942704200745\n",
      "2350 - discriminator loss: 0.7029922008514404 - adversarial loss: 0.63749760389328\n",
      "2375 - discriminator loss: 0.6937180757522583 - adversarial loss: 0.6514348983764648\n",
      "2400 - discriminator loss: 0.6977934837341309 - adversarial loss: 0.6872990727424622\n",
      "2425 - discriminator loss: 0.6940937042236328 - adversarial loss: 0.6446769833564758\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2450 - discriminator loss: 0.6869555115699768 - adversarial loss: 0.6782206296920776\n",
      "2475 - discriminator loss: 0.6953171491622925 - adversarial loss: 0.6966924667358398\n",
      "2500 - discriminator loss: 0.6823137998580933 - adversarial loss: 0.6192054748535156\n",
      "2525 - discriminator loss: 0.6946934461593628 - adversarial loss: 0.6739760637283325\n",
      "2550 - discriminator loss: 0.6915527582168579 - adversarial loss: 0.6329765319824219\n",
      "2575 - discriminator loss: 0.6910058259963989 - adversarial loss: 0.6638435125350952\n",
      "2600 - discriminator loss: 0.7095014452934265 - adversarial loss: 0.6072115898132324\n",
      "2625 - discriminator loss: 0.7023853063583374 - adversarial loss: 0.5993171334266663\n",
      "2650 - discriminator loss: 0.6936624050140381 - adversarial loss: 0.634710431098938\n",
      "2675 - discriminator loss: 0.6888272762298584 - adversarial loss: 0.6888778805732727\n",
      "2700 - discriminator loss: 0.6918286085128784 - adversarial loss: 0.6521841287612915\n",
      "2725 - discriminator loss: 0.683228075504303 - adversarial loss: 0.6480428576469421\n",
      "2750 - discriminator loss: 0.6838147640228271 - adversarial loss: 0.6914613246917725\n",
      "2775 - discriminator loss: 0.6946313381195068 - adversarial loss: 0.6288523077964783\n",
      "2800 - discriminator loss: 0.6937963962554932 - adversarial loss: 0.6672383546829224\n",
      "2825 - discriminator loss: 0.6959835290908813 - adversarial loss: 0.6787570714950562\n",
      "2850 - discriminator loss: 0.6956892609596252 - adversarial loss: 0.6451232433319092\n",
      "2875 - discriminator loss: 0.6862019300460815 - adversarial loss: 0.6561847925186157\n",
      "2900 - discriminator loss: 0.672800600528717 - adversarial loss: 0.8255057334899902\n",
      "2925 - discriminator loss: 0.688148558139801 - adversarial loss: 0.671079158782959\n",
      "2950 - discriminator loss: 0.7015432119369507 - adversarial loss: 0.6308202743530273\n",
      "2975 - discriminator loss: 0.6958827376365662 - adversarial loss: 0.6716060042381287\n",
      "3000 - discriminator loss: 0.6940136551856995 - adversarial loss: 0.6649592518806458\n",
      "3025 - discriminator loss: 0.6972292065620422 - adversarial loss: 0.6677373647689819\n",
      "3050 - discriminator loss: 0.6824623346328735 - adversarial loss: 0.6789215803146362\n",
      "3075 - discriminator loss: 0.6753599047660828 - adversarial loss: 0.6557378768920898\n",
      "3100 - discriminator loss: 0.6871013045310974 - adversarial loss: 0.662605881690979\n",
      "3125 - discriminator loss: 0.6824442148208618 - adversarial loss: 0.6380445957183838\n",
      "3150 - discriminator loss: 0.693101167678833 - adversarial loss: 0.6658450961112976\n",
      "3175 - discriminator loss: 0.7041480541229248 - adversarial loss: 0.6307370066642761\n",
      "3200 - discriminator loss: 0.6862574815750122 - adversarial loss: 0.6484397649765015\n",
      "3225 - discriminator loss: 0.6819456815719604 - adversarial loss: 0.6937683820724487\n",
      "3250 - discriminator loss: 0.6880483031272888 - adversarial loss: 0.6626518964767456\n",
      "3275 - discriminator loss: 0.6880283355712891 - adversarial loss: 0.6620372533798218\n",
      "3300 - discriminator loss: 0.7063361406326294 - adversarial loss: 0.6567426919937134\n",
      "3325 - discriminator loss: 0.6993566751480103 - adversarial loss: 0.6325894594192505\n",
      "3350 - discriminator loss: 0.6867115497589111 - adversarial loss: 0.6538658738136292\n",
      "3375 - discriminator loss: 0.6953575611114502 - adversarial loss: 0.7072992920875549\n",
      "3400 - discriminator loss: 0.6845830082893372 - adversarial loss: 0.7350505590438843\n",
      "3425 - discriminator loss: 0.6850277185440063 - adversarial loss: 0.6477689743041992\n",
      "3450 - discriminator loss: 0.6719965934753418 - adversarial loss: 0.8325003385543823\n",
      "3475 - discriminator loss: 0.7049854397773743 - adversarial loss: 0.6419084072113037\n",
      "3500 - discriminator loss: 0.6768876910209656 - adversarial loss: 0.6786190867424011\n",
      "3525 - discriminator loss: 0.7632743120193481 - adversarial loss: 0.6018474698066711\n",
      "3550 - discriminator loss: 0.7326809167861938 - adversarial loss: 0.5966639518737793\n",
      "3575 - discriminator loss: 0.6764407157897949 - adversarial loss: 0.7386399507522583\n",
      "3600 - discriminator loss: 0.6938384771347046 - adversarial loss: 0.6835456490516663\n",
      "3625 - discriminator loss: 0.7135887742042542 - adversarial loss: 0.6420782804489136\n",
      "3650 - discriminator loss: 0.7031137943267822 - adversarial loss: 0.6934239864349365\n",
      "3675 - discriminator loss: 0.7767440676689148 - adversarial loss: 0.6220711469650269\n",
      "3700 - discriminator loss: 0.6971244812011719 - adversarial loss: 0.6538877487182617\n",
      "3725 - discriminator loss: 0.7066570520401001 - adversarial loss: 0.6768894195556641\n",
      "3750 - discriminator loss: 0.690892219543457 - adversarial loss: 0.6834263205528259\n",
      "3775 - discriminator loss: 0.6834750175476074 - adversarial loss: 0.7394884824752808\n",
      "3800 - discriminator loss: 0.6924134492874146 - adversarial loss: 0.6934081315994263\n",
      "3825 - discriminator loss: 0.69053715467453 - adversarial loss: 0.6591191291809082\n",
      "3850 - discriminator loss: 0.6959383487701416 - adversarial loss: 0.654151976108551\n",
      "3875 - discriminator loss: 0.638427734375 - adversarial loss: 0.716599702835083\n",
      "3900 - discriminator loss: 0.6924936771392822 - adversarial loss: 0.6710755825042725\n",
      "3925 - discriminator loss: 0.6915366053581238 - adversarial loss: 0.6595202088356018\n",
      "3950 - discriminator loss: 0.7281408905982971 - adversarial loss: 0.6786143779754639\n",
      "3975 - discriminator loss: 0.6991788744926453 - adversarial loss: 0.6390937566757202\n",
      "4000 - discriminator loss: 0.6772815585136414 - adversarial loss: 0.65894615650177\n",
      "4025 - discriminator loss: 0.6873307228088379 - adversarial loss: 0.6371257305145264\n",
      "4050 - discriminator loss: 0.700341522693634 - adversarial loss: 0.6578364968299866\n",
      "4075 - discriminator loss: 0.6986688375473022 - adversarial loss: 0.7028337717056274\n",
      "4100 - discriminator loss: 0.7208425402641296 - adversarial loss: 0.6203534007072449\n",
      "4125 - discriminator loss: 0.683746874332428 - adversarial loss: 0.6367449760437012\n",
      "4150 - discriminator loss: 0.674511194229126 - adversarial loss: 0.7543964385986328\n",
      "4175 - discriminator loss: 0.7071618437767029 - adversarial loss: 0.6496028900146484\n",
      "4200 - discriminator loss: 0.6958892345428467 - adversarial loss: 0.694969117641449\n",
      "4225 - discriminator loss: 0.6912099123001099 - adversarial loss: 0.7112667560577393\n",
      "4250 - discriminator loss: 0.6743384003639221 - adversarial loss: 0.7053660154342651\n",
      "4275 - discriminator loss: 0.7004764676094055 - adversarial loss: 0.6273683309555054\n",
      "4300 - discriminator loss: 0.6917343735694885 - adversarial loss: 0.6686537265777588\n",
      "4325 - discriminator loss: 0.6916886568069458 - adversarial loss: 0.6634327173233032\n",
      "4350 - discriminator loss: 0.6969782114028931 - adversarial loss: 0.6801655292510986\n",
      "4375 - discriminator loss: 0.6944011449813843 - adversarial loss: 0.6765167117118835\n",
      "4400 - discriminator loss: 0.6966707706451416 - adversarial loss: 0.6604657173156738\n",
      "4425 - discriminator loss: 0.7012579441070557 - adversarial loss: 0.6963943839073181\n",
      "4450 - discriminator loss: 0.6946210265159607 - adversarial loss: 0.6828113794326782\n",
      "4475 - discriminator loss: 0.6946297883987427 - adversarial loss: 0.6773520708084106\n",
      "4500 - discriminator loss: 0.7035141587257385 - adversarial loss: 0.6560871601104736\n",
      "4525 - discriminator loss: 0.6715505123138428 - adversarial loss: 0.6981152296066284\n",
      "4550 - discriminator loss: 0.6986953020095825 - adversarial loss: 0.6379314064979553\n",
      "4575 - discriminator loss: 0.6984223127365112 - adversarial loss: 0.6382509469985962\n",
      "4600 - discriminator loss: 0.7068096995353699 - adversarial loss: 0.6713483333587646\n",
      "4625 - discriminator loss: 0.6980484127998352 - adversarial loss: 0.7121272087097168\n",
      "4650 - discriminator loss: 0.6984800696372986 - adversarial loss: 0.64305579662323\n",
      "4675 - discriminator loss: 0.6940346360206604 - adversarial loss: 0.6800957322120667\n",
      "4700 - discriminator loss: 0.6839786171913147 - adversarial loss: 0.6114055514335632\n",
      "4725 - discriminator loss: 0.6874181032180786 - adversarial loss: 0.6673449277877808\n",
      "4750 - discriminator loss: 0.6969237923622131 - adversarial loss: 0.6353658437728882\n",
      "4775 - discriminator loss: 0.6973342299461365 - adversarial loss: 0.6540175676345825\n",
      "4800 - discriminator loss: 0.6870633959770203 - adversarial loss: 0.6496717929840088\n",
      "4825 - discriminator loss: 0.6943802833557129 - adversarial loss: 0.662034273147583\n",
      "4850 - discriminator loss: 0.7085016965866089 - adversarial loss: 0.664006769657135\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4875 - discriminator loss: 0.6885538101196289 - adversarial loss: 0.6777774095535278\n",
      "4900 - discriminator loss: 0.6903725862503052 - adversarial loss: 0.6913822889328003\n",
      "4925 - discriminator loss: 0.6983163356781006 - adversarial loss: 0.6677148938179016\n",
      "4950 - discriminator loss: 0.6873525381088257 - adversarial loss: 0.6469400525093079\n",
      "4975 - discriminator loss: 0.6966453194618225 - adversarial loss: 0.6563756465911865\n",
      "5000 - discriminator loss: 0.6980607509613037 - adversarial loss: 0.6858335733413696\n",
      "5025 - discriminator loss: 0.7046037912368774 - adversarial loss: 0.6310698986053467\n",
      "5050 - discriminator loss: 0.7108476161956787 - adversarial loss: 0.6882312893867493\n",
      "5075 - discriminator loss: 0.689849317073822 - adversarial loss: 0.6548662185668945\n",
      "5100 - discriminator loss: 0.692882776260376 - adversarial loss: 0.6935901641845703\n",
      "5125 - discriminator loss: 0.7019450664520264 - adversarial loss: 0.660699188709259\n",
      "5150 - discriminator loss: 0.6943239569664001 - adversarial loss: 0.6693764925003052\n",
      "5175 - discriminator loss: 0.7023866176605225 - adversarial loss: 0.6675257682800293\n",
      "5200 - discriminator loss: 0.6972814798355103 - adversarial loss: 0.6458885669708252\n",
      "5225 - discriminator loss: 0.6931949257850647 - adversarial loss: 0.6327470541000366\n",
      "5250 - discriminator loss: 0.6900041103363037 - adversarial loss: 0.6426330804824829\n",
      "5275 - discriminator loss: 0.6861938238143921 - adversarial loss: 0.6552697420120239\n",
      "5300 - discriminator loss: 0.6926195025444031 - adversarial loss: 0.6699712872505188\n",
      "5325 - discriminator loss: 0.6926122903823853 - adversarial loss: 0.6840353608131409\n",
      "5350 - discriminator loss: 0.6906987428665161 - adversarial loss: 0.6335371732711792\n",
      "5375 - discriminator loss: 0.6903586983680725 - adversarial loss: 0.6533631086349487\n",
      "5400 - discriminator loss: 0.6990102529525757 - adversarial loss: 0.662647545337677\n",
      "5425 - discriminator loss: 0.6895608305931091 - adversarial loss: 0.6718916893005371\n",
      "5450 - discriminator loss: 0.6969987154006958 - adversarial loss: 0.6747450828552246\n",
      "5475 - discriminator loss: 0.6871367692947388 - adversarial loss: 0.652901828289032\n",
      "5500 - discriminator loss: 0.6893317699432373 - adversarial loss: 0.6546221971511841\n",
      "5525 - discriminator loss: 0.6897693872451782 - adversarial loss: 0.661853551864624\n",
      "5550 - discriminator loss: 0.7069362998008728 - adversarial loss: 0.6543495059013367\n",
      "5575 - discriminator loss: 0.7008954286575317 - adversarial loss: 0.6701083183288574\n",
      "5600 - discriminator loss: 0.6967803239822388 - adversarial loss: 0.6984707713127136\n",
      "5625 - discriminator loss: 0.6912166476249695 - adversarial loss: 0.680144190788269\n",
      "5650 - discriminator loss: 0.6969001293182373 - adversarial loss: 0.6579784154891968\n",
      "5675 - discriminator loss: 0.7003705501556396 - adversarial loss: 0.6867200136184692\n",
      "5700 - discriminator loss: 0.6950207352638245 - adversarial loss: 0.6620500087738037\n",
      "5725 - discriminator loss: 0.6947900056838989 - adversarial loss: 0.6685116291046143\n",
      "5750 - discriminator loss: 0.6934345960617065 - adversarial loss: 0.6403276920318604\n",
      "5775 - discriminator loss: 0.6923487186431885 - adversarial loss: 0.7140811681747437\n",
      "5800 - discriminator loss: 0.6999779939651489 - adversarial loss: 0.6678594946861267\n",
      "5825 - discriminator loss: 0.6902758479118347 - adversarial loss: 0.6705698370933533\n",
      "5850 - discriminator loss: 0.6911507844924927 - adversarial loss: 0.6671777963638306\n",
      "5875 - discriminator loss: 0.7014182209968567 - adversarial loss: 0.6230756044387817\n",
      "5900 - discriminator loss: 0.6998727321624756 - adversarial loss: 0.6413737535476685\n",
      "5925 - discriminator loss: 0.6888852119445801 - adversarial loss: 0.698821485042572\n",
      "5950 - discriminator loss: 0.7104474306106567 - adversarial loss: 0.6635922193527222\n",
      "5975 - discriminator loss: 0.6869972944259644 - adversarial loss: 0.6778092384338379\n",
      "6000 - discriminator loss: 0.6947903633117676 - adversarial loss: 0.6264445781707764\n",
      "6025 - discriminator loss: 0.6877902746200562 - adversarial loss: 0.6805905103683472\n",
      "6050 - discriminator loss: 0.6861736178398132 - adversarial loss: 0.6771489381790161\n",
      "6075 - discriminator loss: 0.7001776695251465 - adversarial loss: 0.6746324896812439\n",
      "6100 - discriminator loss: 0.6873191595077515 - adversarial loss: 0.6525861024856567\n",
      "6125 - discriminator loss: 0.7075743675231934 - adversarial loss: 0.687976598739624\n",
      "6150 - discriminator loss: 0.694839596748352 - adversarial loss: 0.6922386884689331\n",
      "6175 - discriminator loss: 0.6885461807250977 - adversarial loss: 0.6746535897254944\n",
      "6200 - discriminator loss: 0.6924650073051453 - adversarial loss: 0.6372596025466919\n",
      "6225 - discriminator loss: 0.692612886428833 - adversarial loss: 0.6622995138168335\n",
      "6250 - discriminator loss: 0.6894737482070923 - adversarial loss: 0.6720364093780518\n",
      "6275 - discriminator loss: 0.6947758793830872 - adversarial loss: 0.6864480376243591\n",
      "6300 - discriminator loss: 0.6976293325424194 - adversarial loss: 0.642947793006897\n",
      "6325 - discriminator loss: 0.6913533210754395 - adversarial loss: 0.6479921936988831\n",
      "6350 - discriminator loss: 0.6948370337486267 - adversarial loss: 0.6670502424240112\n",
      "6375 - discriminator loss: 0.6887791752815247 - adversarial loss: 0.6607688069343567\n",
      "6400 - discriminator loss: 0.6939569711685181 - adversarial loss: 0.6448847055435181\n",
      "6425 - discriminator loss: 0.6845471858978271 - adversarial loss: 0.6548356413841248\n",
      "6450 - discriminator loss: 0.6963863968849182 - adversarial loss: 0.6542482376098633\n",
      "6475 - discriminator loss: 0.6860947608947754 - adversarial loss: 0.7276043891906738\n",
      "6500 - discriminator loss: 0.694475531578064 - adversarial loss: 0.6330884695053101\n",
      "6525 - discriminator loss: 0.7014291286468506 - adversarial loss: 0.6727448105812073\n",
      "6550 - discriminator loss: 0.6955181360244751 - adversarial loss: 0.6316854953765869\n",
      "6575 - discriminator loss: 0.7008810639381409 - adversarial loss: 0.6349722146987915\n",
      "6600 - discriminator loss: 0.6940848231315613 - adversarial loss: 0.6517214179039001\n",
      "6625 - discriminator loss: 0.6933186054229736 - adversarial loss: 0.7058993577957153\n",
      "6650 - discriminator loss: 0.6987888813018799 - adversarial loss: 0.6321955919265747\n",
      "6675 - discriminator loss: 0.7020850777626038 - adversarial loss: 0.6391885280609131\n",
      "6700 - discriminator loss: 0.6949076652526855 - adversarial loss: 0.6709079742431641\n",
      "6725 - discriminator loss: 0.6960933804512024 - adversarial loss: 0.6396684050559998\n",
      "6750 - discriminator loss: 0.6858410835266113 - adversarial loss: 0.6264059543609619\n",
      "6775 - discriminator loss: 0.6902974843978882 - adversarial loss: 0.6869734525680542\n",
      "6800 - discriminator loss: 0.6978877782821655 - adversarial loss: 0.6295986771583557\n",
      "6825 - discriminator loss: 0.6951428651809692 - adversarial loss: 0.6600170135498047\n",
      "6850 - discriminator loss: 0.6921637058258057 - adversarial loss: 0.640526294708252\n",
      "6875 - discriminator loss: 0.693832516670227 - adversarial loss: 0.6446971893310547\n",
      "6900 - discriminator loss: 0.7017637491226196 - adversarial loss: 0.6867650151252747\n",
      "6925 - discriminator loss: 0.6858005523681641 - adversarial loss: 0.6577932834625244\n",
      "6950 - discriminator loss: 0.6919752359390259 - adversarial loss: 0.6249570250511169\n",
      "6975 - discriminator loss: 0.6898003816604614 - adversarial loss: 0.6607723236083984\n",
      "7000 - discriminator loss: 0.693337619304657 - adversarial loss: 0.6650968790054321\n",
      "7025 - discriminator loss: 0.6958834528923035 - adversarial loss: 0.6754587888717651\n",
      "7050 - discriminator loss: 0.6822746396064758 - adversarial loss: 0.6287601590156555\n",
      "7075 - discriminator loss: 0.6945437788963318 - adversarial loss: 0.6279781460762024\n",
      "7100 - discriminator loss: 0.6887916922569275 - adversarial loss: 0.6121342778205872\n",
      "7125 - discriminator loss: 0.6898224949836731 - adversarial loss: 0.6401947736740112\n",
      "7150 - discriminator loss: 0.6988407373428345 - adversarial loss: 0.6197527050971985\n",
      "7175 - discriminator loss: 0.6913261413574219 - adversarial loss: 0.654448390007019\n",
      "7200 - discriminator loss: 0.6828404664993286 - adversarial loss: 0.691531777381897\n",
      "7225 - discriminator loss: 0.6760072708129883 - adversarial loss: 0.6255356669425964\n",
      "7250 - discriminator loss: 0.7124509811401367 - adversarial loss: 0.670202374458313\n",
      "7275 - discriminator loss: 0.6955969929695129 - adversarial loss: 0.6574766039848328\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7300 - discriminator loss: 0.7134043574333191 - adversarial loss: 0.6720666885375977\n",
      "7325 - discriminator loss: 0.6992075443267822 - adversarial loss: 0.6479027271270752\n",
      "7350 - discriminator loss: 0.6929045915603638 - adversarial loss: 0.6740367412567139\n",
      "7375 - discriminator loss: 0.6904016733169556 - adversarial loss: 0.6293584108352661\n",
      "7400 - discriminator loss: 0.695609450340271 - adversarial loss: 0.6590521335601807\n",
      "7425 - discriminator loss: 0.7003505825996399 - adversarial loss: 0.718238115310669\n",
      "7450 - discriminator loss: 0.6961654424667358 - adversarial loss: 0.6457960605621338\n",
      "7475 - discriminator loss: 0.696922242641449 - adversarial loss: 0.6290993690490723\n",
      "7500 - discriminator loss: 0.6923460364341736 - adversarial loss: 0.6411067843437195\n",
      "7525 - discriminator loss: 0.6957598924636841 - adversarial loss: 0.6750596761703491\n",
      "7550 - discriminator loss: 0.6899393796920776 - adversarial loss: 0.6686040163040161\n",
      "7575 - discriminator loss: 0.692267894744873 - adversarial loss: 0.6235475540161133\n",
      "7600 - discriminator loss: 0.6928524971008301 - adversarial loss: 0.6381646990776062\n",
      "7625 - discriminator loss: 0.6970665454864502 - adversarial loss: 0.6412642002105713\n",
      "7650 - discriminator loss: 0.696785569190979 - adversarial loss: 0.6525111198425293\n",
      "7675 - discriminator loss: 0.6943393349647522 - adversarial loss: 0.6585445404052734\n",
      "7700 - discriminator loss: 0.6810389161109924 - adversarial loss: 0.706183135509491\n",
      "7725 - discriminator loss: 0.6833527684211731 - adversarial loss: 0.6810461282730103\n",
      "7750 - discriminator loss: 0.6949343681335449 - adversarial loss: 0.6578052043914795\n",
      "7775 - discriminator loss: 0.6941800713539124 - adversarial loss: 0.6642234921455383\n",
      "7800 - discriminator loss: 0.6961179375648499 - adversarial loss: 0.6514211893081665\n",
      "7825 - discriminator loss: 0.7024986743927002 - adversarial loss: 0.6359508037567139\n",
      "7850 - discriminator loss: 0.6990112066268921 - adversarial loss: 0.6733443737030029\n",
      "7875 - discriminator loss: 0.6969280242919922 - adversarial loss: 0.6312838196754456\n",
      "7900 - discriminator loss: 0.6877725720405579 - adversarial loss: 0.6236559152603149\n",
      "7925 - discriminator loss: 0.69866544008255 - adversarial loss: 0.6650303602218628\n",
      "7950 - discriminator loss: 0.7016441822052002 - adversarial loss: 0.6729051470756531\n",
      "7975 - discriminator loss: 0.6886928677558899 - adversarial loss: 0.6867367029190063\n",
      "8000 - discriminator loss: 0.7184664011001587 - adversarial loss: 0.6958387494087219\n",
      "8025 - discriminator loss: 0.6997706890106201 - adversarial loss: 0.6573573350906372\n",
      "8050 - discriminator loss: 0.6915233731269836 - adversarial loss: 0.6751515865325928\n",
      "8075 - discriminator loss: 0.6875233054161072 - adversarial loss: 0.6436926126480103\n",
      "8100 - discriminator loss: 0.6964461207389832 - adversarial loss: 0.6496372818946838\n",
      "8125 - discriminator loss: 0.6975417137145996 - adversarial loss: 0.6853504180908203\n",
      "8150 - discriminator loss: 0.6913506984710693 - adversarial loss: 0.646517813205719\n",
      "8175 - discriminator loss: 0.6907362937927246 - adversarial loss: 0.6405593156814575\n",
      "8200 - discriminator loss: 0.6918491721153259 - adversarial loss: 0.6440633535385132\n",
      "8225 - discriminator loss: 0.6934877634048462 - adversarial loss: 0.6272746324539185\n",
      "8250 - discriminator loss: 0.6934377551078796 - adversarial loss: 0.6738955974578857\n",
      "8275 - discriminator loss: 0.6986839771270752 - adversarial loss: 0.6644880771636963\n",
      "8300 - discriminator loss: 0.6885711550712585 - adversarial loss: 0.6258074045181274\n",
      "8325 - discriminator loss: 0.6996407508850098 - adversarial loss: 0.6407731175422668\n",
      "8350 - discriminator loss: 0.6918248534202576 - adversarial loss: 0.6713018417358398\n",
      "8375 - discriminator loss: 0.689410388469696 - adversarial loss: 0.6859313249588013\n",
      "8400 - discriminator loss: 0.6916987895965576 - adversarial loss: 0.6326891183853149\n",
      "8425 - discriminator loss: 0.6896857023239136 - adversarial loss: 0.6945189833641052\n",
      "8450 - discriminator loss: 0.6906471252441406 - adversarial loss: 0.6352677345275879\n",
      "8475 - discriminator loss: 0.7042859792709351 - adversarial loss: 0.6183741092681885\n",
      "8500 - discriminator loss: 0.6993189454078674 - adversarial loss: 0.6465602517127991\n",
      "8525 - discriminator loss: 0.6892432570457458 - adversarial loss: 0.6466110944747925\n",
      "8550 - discriminator loss: 0.6917479634284973 - adversarial loss: 0.6516780853271484\n",
      "8575 - discriminator loss: 0.6854225993156433 - adversarial loss: 0.6080834865570068\n",
      "8600 - discriminator loss: 0.7012932300567627 - adversarial loss: 0.6800336837768555\n",
      "8625 - discriminator loss: 0.7002135515213013 - adversarial loss: 0.6619445085525513\n",
      "8650 - discriminator loss: 0.6884941458702087 - adversarial loss: 0.6547908782958984\n",
      "8675 - discriminator loss: 0.6945738792419434 - adversarial loss: 0.6705254316329956\n",
      "8700 - discriminator loss: 0.6947545409202576 - adversarial loss: 0.6533974409103394\n",
      "8725 - discriminator loss: 0.6924412250518799 - adversarial loss: 0.6812076568603516\n",
      "8750 - discriminator loss: 0.6899119019508362 - adversarial loss: 0.6424554586410522\n",
      "8775 - discriminator loss: 0.6921982765197754 - adversarial loss: 0.6520921587944031\n",
      "8800 - discriminator loss: 0.6992064118385315 - adversarial loss: 0.6748709678649902\n",
      "8825 - discriminator loss: 0.6973775625228882 - adversarial loss: 0.6541741490364075\n",
      "8850 - discriminator loss: 0.6914789080619812 - adversarial loss: 0.6869116425514221\n",
      "8875 - discriminator loss: 0.7000852823257446 - adversarial loss: 0.6397767066955566\n",
      "8900 - discriminator loss: 0.7061810493469238 - adversarial loss: 0.6659571528434753\n",
      "8925 - discriminator loss: 0.6935895681381226 - adversarial loss: 0.6502511501312256\n",
      "8950 - discriminator loss: 0.693549633026123 - adversarial loss: 0.6539663076400757\n",
      "8975 - discriminator loss: 0.6954250335693359 - adversarial loss: 0.661814272403717\n",
      "9000 - discriminator loss: 0.7024743556976318 - adversarial loss: 0.640453577041626\n",
      "9025 - discriminator loss: 0.6972647309303284 - adversarial loss: 0.6638441681861877\n",
      "9050 - discriminator loss: 0.6918798685073853 - adversarial loss: 0.6543135046958923\n",
      "9075 - discriminator loss: 0.6934022903442383 - adversarial loss: 0.6636468172073364\n",
      "9100 - discriminator loss: 0.6955691576004028 - adversarial loss: 0.6543095111846924\n",
      "9125 - discriminator loss: 0.6963626146316528 - adversarial loss: 0.649771511554718\n",
      "9150 - discriminator loss: 0.6905717849731445 - adversarial loss: 0.6603258848190308\n",
      "9175 - discriminator loss: 0.6993229985237122 - adversarial loss: 0.7146283388137817\n",
      "9200 - discriminator loss: 0.6939892768859863 - adversarial loss: 0.6686182618141174\n",
      "9225 - discriminator loss: 0.7062157392501831 - adversarial loss: 0.6259274482727051\n",
      "9250 - discriminator loss: 0.7014408111572266 - adversarial loss: 0.6591386795043945\n",
      "9275 - discriminator loss: 0.6932396292686462 - adversarial loss: 0.6802568435668945\n",
      "9300 - discriminator loss: 0.6884992122650146 - adversarial loss: 0.6362274885177612\n",
      "9325 - discriminator loss: 0.6989448666572571 - adversarial loss: 0.6547672748565674\n",
      "9350 - discriminator loss: 0.6994946002960205 - adversarial loss: 0.6388996839523315\n",
      "9375 - discriminator loss: 0.7100988626480103 - adversarial loss: 0.671528697013855\n",
      "9400 - discriminator loss: 0.7029064297676086 - adversarial loss: 0.6292339563369751\n",
      "9425 - discriminator loss: 0.6928764581680298 - adversarial loss: 0.6582098007202148\n",
      "9450 - discriminator loss: 0.6934514045715332 - adversarial loss: 0.6681402921676636\n",
      "9475 - discriminator loss: 0.6931226253509521 - adversarial loss: 0.6453099250793457\n",
      "9500 - discriminator loss: 0.6959576606750488 - adversarial loss: 0.6829714179039001\n",
      "9525 - discriminator loss: 0.6921365261077881 - adversarial loss: 0.6606804132461548\n",
      "9550 - discriminator loss: 0.690028727054596 - adversarial loss: 0.676429033279419\n",
      "9575 - discriminator loss: 0.6971787214279175 - adversarial loss: 0.6549590826034546\n",
      "9600 - discriminator loss: 0.6966286897659302 - adversarial loss: 0.6377858519554138\n",
      "9625 - discriminator loss: 0.6986576914787292 - adversarial loss: 0.6584458351135254\n",
      "9650 - discriminator loss: 0.6904540061950684 - adversarial loss: 0.6467316150665283\n",
      "9675 - discriminator loss: 0.6945552825927734 - adversarial loss: 0.655353307723999\n",
      "9700 - discriminator loss: 0.6964367628097534 - adversarial loss: 0.6654607057571411\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9725 - discriminator loss: 0.6945909261703491 - adversarial loss: 0.6811840534210205\n",
      "9750 - discriminator loss: 0.697429895401001 - adversarial loss: 0.6478967666625977\n",
      "9775 - discriminator loss: 0.6854397058486938 - adversarial loss: 0.6461321115493774\n",
      "9800 - discriminator loss: 0.7019248008728027 - adversarial loss: 0.6677196025848389\n",
      "9825 - discriminator loss: 0.6893069744110107 - adversarial loss: 0.6555277109146118\n",
      "9850 - discriminator loss: 0.6956192851066589 - adversarial loss: 0.6516340970993042\n",
      "9875 - discriminator loss: 0.6987451314926147 - adversarial loss: 0.6379444599151611\n",
      "9900 - discriminator loss: 0.7173001170158386 - adversarial loss: 0.6345551013946533\n",
      "9925 - discriminator loss: 0.6953607797622681 - adversarial loss: 0.6471492052078247\n",
      "9950 - discriminator loss: 0.6983697414398193 - adversarial loss: 0.6678364276885986\n",
      "9975 - discriminator loss: 0.6863130331039429 - adversarial loss: 0.6643017530441284\n",
      "10000 - discriminator loss: 0.6993637681007385 - adversarial loss: 0.6474342346191406\n",
      "10025 - discriminator loss: 0.6950454711914062 - adversarial loss: 0.6351296901702881\n",
      "10050 - discriminator loss: 0.6914591789245605 - adversarial loss: 0.645341157913208\n",
      "10075 - discriminator loss: 0.6998960971832275 - adversarial loss: 0.6440550088882446\n",
      "10100 - discriminator loss: 0.6996849775314331 - adversarial loss: 0.6360082030296326\n",
      "10125 - discriminator loss: 0.6982685327529907 - adversarial loss: 0.6471017003059387\n",
      "10150 - discriminator loss: 0.6923617720603943 - adversarial loss: 0.6559829711914062\n",
      "10175 - discriminator loss: 0.6935376524925232 - adversarial loss: 0.6337326169013977\n",
      "10200 - discriminator loss: 0.6937274932861328 - adversarial loss: 0.6627172231674194\n",
      "10225 - discriminator loss: 0.6924985647201538 - adversarial loss: 0.6457494497299194\n",
      "10250 - discriminator loss: 0.6932027339935303 - adversarial loss: 0.6427950859069824\n",
      "10275 - discriminator loss: 0.6997853517532349 - adversarial loss: 0.6599594354629517\n",
      "10300 - discriminator loss: 0.6924203634262085 - adversarial loss: 0.6644319295883179\n",
      "10325 - discriminator loss: 0.7106055617332458 - adversarial loss: 0.6611595153808594\n",
      "10350 - discriminator loss: 0.6951581239700317 - adversarial loss: 0.6602251529693604\n",
      "10375 - discriminator loss: 0.6947808265686035 - adversarial loss: 0.6767483949661255\n",
      "10400 - discriminator loss: 0.6841729283332825 - adversarial loss: 0.6162809133529663\n",
      "10425 - discriminator loss: 0.7023278474807739 - adversarial loss: 0.6589963436126709\n",
      "10450 - discriminator loss: 0.6952778100967407 - adversarial loss: 0.6705455780029297\n",
      "10475 - discriminator loss: 0.6936121582984924 - adversarial loss: 0.6683489680290222\n",
      "10500 - discriminator loss: 0.6903984546661377 - adversarial loss: 0.6607892513275146\n",
      "10525 - discriminator loss: 0.6901344060897827 - adversarial loss: 0.6516284942626953\n",
      "10550 - discriminator loss: 0.6928842663764954 - adversarial loss: 0.6508181095123291\n",
      "10575 - discriminator loss: 0.6972535252571106 - adversarial loss: 0.6263971328735352\n",
      "10600 - discriminator loss: 0.6922004222869873 - adversarial loss: 0.6876888275146484\n",
      "10625 - discriminator loss: 0.6936759352684021 - adversarial loss: 0.6604363322257996\n",
      "10650 - discriminator loss: 0.6884523630142212 - adversarial loss: 0.6552126407623291\n",
      "10675 - discriminator loss: 0.6981566548347473 - adversarial loss: 0.6484053134918213\n",
      "10700 - discriminator loss: 0.6938855648040771 - adversarial loss: 0.6654625535011292\n",
      "10725 - discriminator loss: 0.6942263245582581 - adversarial loss: 0.6270350813865662\n",
      "10750 - discriminator loss: 0.6898512840270996 - adversarial loss: 0.6470845341682434\n",
      "10775 - discriminator loss: 0.6971268653869629 - adversarial loss: 0.6488370895385742\n",
      "10800 - discriminator loss: 0.6929807066917419 - adversarial loss: 0.6657018661499023\n",
      "10825 - discriminator loss: 0.6939821839332581 - adversarial loss: 0.6723949909210205\n",
      "10850 - discriminator loss: 0.6977319121360779 - adversarial loss: 0.6423530578613281\n",
      "10875 - discriminator loss: 0.6841913461685181 - adversarial loss: 0.6704850792884827\n",
      "10900 - discriminator loss: 0.689276933670044 - adversarial loss: 0.6563379168510437\n",
      "10925 - discriminator loss: 0.7055165767669678 - adversarial loss: 0.6636064052581787\n",
      "10950 - discriminator loss: 0.6994655728340149 - adversarial loss: 0.6518902778625488\n",
      "10975 - discriminator loss: 0.7015268206596375 - adversarial loss: 0.630986213684082\n",
      "11000 - discriminator loss: 0.6870834827423096 - adversarial loss: 0.6584480404853821\n",
      "11025 - discriminator loss: 0.7025499939918518 - adversarial loss: 0.6722416281700134\n",
      "11050 - discriminator loss: 0.6975972652435303 - adversarial loss: 0.624748706817627\n",
      "11075 - discriminator loss: 0.6874569058418274 - adversarial loss: 0.6680939793586731\n",
      "11100 - discriminator loss: 0.6909668445587158 - adversarial loss: 0.6525527834892273\n",
      "11125 - discriminator loss: 0.6957739591598511 - adversarial loss: 0.6448497176170349\n",
      "11150 - discriminator loss: 0.6932754516601562 - adversarial loss: 0.646604061126709\n",
      "11175 - discriminator loss: 0.6877003312110901 - adversarial loss: 0.629304051399231\n",
      "11200 - discriminator loss: 0.6872159242630005 - adversarial loss: 0.7059333324432373\n",
      "11225 - discriminator loss: 0.6929712891578674 - adversarial loss: 0.6399153470993042\n",
      "11250 - discriminator loss: 0.6916518211364746 - adversarial loss: 0.6235471963882446\n",
      "11275 - discriminator loss: 0.6958335041999817 - adversarial loss: 0.6666523814201355\n",
      "11300 - discriminator loss: 0.6910090446472168 - adversarial loss: 0.6380430459976196\n",
      "11325 - discriminator loss: 0.6910257339477539 - adversarial loss: 0.6648843288421631\n",
      "11350 - discriminator loss: 0.7037993669509888 - adversarial loss: 0.6510978937149048\n",
      "11375 - discriminator loss: 0.7036733627319336 - adversarial loss: 0.6533810496330261\n",
      "11400 - discriminator loss: 0.6958042979240417 - adversarial loss: 0.6465990543365479\n",
      "11425 - discriminator loss: 0.6934182047843933 - adversarial loss: 0.6375803351402283\n",
      "11450 - discriminator loss: 0.705602765083313 - adversarial loss: 0.6390987634658813\n",
      "11475 - discriminator loss: 0.6966173648834229 - adversarial loss: 0.6402606964111328\n",
      "11500 - discriminator loss: 0.6954362392425537 - adversarial loss: 0.6430687308311462\n",
      "11525 - discriminator loss: 0.6890044212341309 - adversarial loss: 0.6564557552337646\n",
      "11550 - discriminator loss: 0.6893842220306396 - adversarial loss: 0.6902850866317749\n",
      "11575 - discriminator loss: 0.6989114284515381 - adversarial loss: 0.6483194828033447\n",
      "11600 - discriminator loss: 0.7005540132522583 - adversarial loss: 0.6274343132972717\n",
      "11625 - discriminator loss: 0.7005261182785034 - adversarial loss: 0.6754317879676819\n",
      "11650 - discriminator loss: 0.6892791986465454 - adversarial loss: 0.6510690450668335\n",
      "11675 - discriminator loss: 0.6932957172393799 - adversarial loss: 0.636864423751831\n",
      "11700 - discriminator loss: 0.6917029619216919 - adversarial loss: 0.6465857028961182\n",
      "11725 - discriminator loss: 0.6936649084091187 - adversarial loss: 0.6773593425750732\n",
      "11750 - discriminator loss: 0.6900056600570679 - adversarial loss: 0.6769804954528809\n",
      "11775 - discriminator loss: 0.6948883533477783 - adversarial loss: 0.6470423936843872\n",
      "11800 - discriminator loss: 0.6926983594894409 - adversarial loss: 0.6514874696731567\n",
      "11825 - discriminator loss: 0.6914309859275818 - adversarial loss: 0.6620851159095764\n",
      "11850 - discriminator loss: 0.6965293884277344 - adversarial loss: 0.6353467702865601\n",
      "11875 - discriminator loss: 0.6879470348358154 - adversarial loss: 0.6304229497909546\n",
      "11900 - discriminator loss: 0.6908248066902161 - adversarial loss: 0.6504250764846802\n",
      "11925 - discriminator loss: 0.7018126845359802 - adversarial loss: 0.6513593196868896\n",
      "11950 - discriminator loss: 0.6921865940093994 - adversarial loss: 0.6531511545181274\n",
      "11975 - discriminator loss: 0.6906212568283081 - adversarial loss: 0.6861517429351807\n",
      "12000 - discriminator loss: 0.6967887878417969 - adversarial loss: 0.6571545600891113\n",
      "12025 - discriminator loss: 0.6851157546043396 - adversarial loss: 0.6701310276985168\n",
      "12050 - discriminator loss: 0.6919615268707275 - adversarial loss: 0.6515103578567505\n",
      "12075 - discriminator loss: 0.6935334205627441 - adversarial loss: 0.674415647983551\n",
      "12100 - discriminator loss: 0.69340980052948 - adversarial loss: 0.6629824638366699\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12125 - discriminator loss: 0.6894451379776001 - adversarial loss: 0.6713483333587646\n",
      "12150 - discriminator loss: 0.6956729888916016 - adversarial loss: 0.6582602262496948\n",
      "12175 - discriminator loss: 0.6920897960662842 - adversarial loss: 0.6640939712524414\n",
      "12200 - discriminator loss: 0.6979538202285767 - adversarial loss: 0.6765854358673096\n",
      "12225 - discriminator loss: 0.6957396268844604 - adversarial loss: 0.6458852291107178\n",
      "12250 - discriminator loss: 0.6905272006988525 - adversarial loss: 0.654316782951355\n",
      "12275 - discriminator loss: 0.7014744281768799 - adversarial loss: 0.6552292108535767\n",
      "12300 - discriminator loss: 0.6952146291732788 - adversarial loss: 0.6656909584999084\n",
      "12325 - discriminator loss: 0.6865420341491699 - adversarial loss: 0.6479511260986328\n",
      "12350 - discriminator loss: 0.6889199018478394 - adversarial loss: 0.6635236740112305\n",
      "12375 - discriminator loss: 0.6890971660614014 - adversarial loss: 0.6767945289611816\n",
      "12400 - discriminator loss: 0.6885914206504822 - adversarial loss: 0.6258519291877747\n",
      "12425 - discriminator loss: 0.6947067975997925 - adversarial loss: 0.6545889377593994\n",
      "12450 - discriminator loss: 0.6954435110092163 - adversarial loss: 0.6574123501777649\n",
      "12475 - discriminator loss: 0.6899830102920532 - adversarial loss: 0.6538218259811401\n",
      "12500 - discriminator loss: 0.6938929557800293 - adversarial loss: 0.6488778591156006\n",
      "12525 - discriminator loss: 0.6952929496765137 - adversarial loss: 0.6616016626358032\n",
      "12550 - discriminator loss: 0.6863296031951904 - adversarial loss: 0.6596081256866455\n",
      "12575 - discriminator loss: 0.6865121722221375 - adversarial loss: 0.630196213722229\n",
      "12600 - discriminator loss: 0.6840656399726868 - adversarial loss: 0.6683400273323059\n",
      "12625 - discriminator loss: 0.6870536804199219 - adversarial loss: 0.6509193181991577\n",
      "12650 - discriminator loss: 0.6895638704299927 - adversarial loss: 0.655397355556488\n",
      "12675 - discriminator loss: 0.6904407143592834 - adversarial loss: 0.6432278156280518\n",
      "12700 - discriminator loss: 0.6904934644699097 - adversarial loss: 0.6814839839935303\n",
      "12725 - discriminator loss: 0.6935789585113525 - adversarial loss: 0.6446453928947449\n",
      "12750 - discriminator loss: 0.6891541481018066 - adversarial loss: 0.6045060157775879\n",
      "12775 - discriminator loss: 0.6909212470054626 - adversarial loss: 0.6650291681289673\n",
      "12800 - discriminator loss: 0.6898049116134644 - adversarial loss: 0.6414440870285034\n",
      "12825 - discriminator loss: 0.692730188369751 - adversarial loss: 0.6404428482055664\n",
      "12850 - discriminator loss: 0.6918184161186218 - adversarial loss: 0.6660997867584229\n",
      "12875 - discriminator loss: 0.6941872835159302 - adversarial loss: 0.6339300870895386\n",
      "12900 - discriminator loss: 0.6889613270759583 - adversarial loss: 0.6684764623641968\n",
      "12925 - discriminator loss: 0.6928316354751587 - adversarial loss: 0.6395880579948425\n",
      "12950 - discriminator loss: 0.6925421357154846 - adversarial loss: 0.6430959701538086\n",
      "12975 - discriminator loss: 0.6911174058914185 - adversarial loss: 0.6760324835777283\n",
      "13000 - discriminator loss: 0.6953532695770264 - adversarial loss: 0.6614782810211182\n",
      "13025 - discriminator loss: 0.6930505037307739 - adversarial loss: 0.6785988807678223\n",
      "13050 - discriminator loss: 0.6857638359069824 - adversarial loss: 0.6744592189788818\n",
      "13075 - discriminator loss: 0.6971451044082642 - adversarial loss: 0.6467183828353882\n",
      "13100 - discriminator loss: 0.6950244307518005 - adversarial loss: 0.6990941166877747\n",
      "13125 - discriminator loss: 0.6934724450111389 - adversarial loss: 0.6480010747909546\n",
      "13150 - discriminator loss: 0.6949144601821899 - adversarial loss: 0.6560626029968262\n",
      "13175 - discriminator loss: 0.6991122961044312 - adversarial loss: 0.6366350650787354\n",
      "13200 - discriminator loss: 0.6906442642211914 - adversarial loss: 0.6425930261611938\n",
      "13225 - discriminator loss: 0.683207094669342 - adversarial loss: 0.6526610851287842\n",
      "13250 - discriminator loss: 0.6861020922660828 - adversarial loss: 0.6346085667610168\n",
      "13275 - discriminator loss: 0.700185239315033 - adversarial loss: 0.6848151683807373\n",
      "13300 - discriminator loss: 0.69317626953125 - adversarial loss: 0.6337692737579346\n",
      "13325 - discriminator loss: 0.6912796497344971 - adversarial loss: 0.6724269390106201\n",
      "13350 - discriminator loss: 0.6939048171043396 - adversarial loss: 0.6549242734909058\n",
      "13375 - discriminator loss: 0.7049465179443359 - adversarial loss: 0.6556811332702637\n",
      "13400 - discriminator loss: 0.6914748549461365 - adversarial loss: 0.6578642129898071\n",
      "13425 - discriminator loss: 0.6866353750228882 - adversarial loss: 0.6439948678016663\n",
      "13450 - discriminator loss: 0.6964831352233887 - adversarial loss: 0.6528439521789551\n",
      "13475 - discriminator loss: 0.688558042049408 - adversarial loss: 0.6410880088806152\n",
      "13500 - discriminator loss: 0.6867038011550903 - adversarial loss: 0.664562463760376\n",
      "13525 - discriminator loss: 0.6905276775360107 - adversarial loss: 0.6341084241867065\n",
      "13550 - discriminator loss: 0.699077844619751 - adversarial loss: 0.6476719379425049\n",
      "13575 - discriminator loss: 0.6929581165313721 - adversarial loss: 0.6627475023269653\n",
      "13600 - discriminator loss: 0.6910240650177002 - adversarial loss: 0.6707360744476318\n",
      "13625 - discriminator loss: 0.6931260824203491 - adversarial loss: 0.6454572081565857\n",
      "13650 - discriminator loss: 0.6943800449371338 - adversarial loss: 0.6373159289360046\n",
      "13675 - discriminator loss: 0.6978761553764343 - adversarial loss: 0.6205111742019653\n",
      "13700 - discriminator loss: 0.7013758420944214 - adversarial loss: 0.6254880428314209\n",
      "13725 - discriminator loss: 0.6926469802856445 - adversarial loss: 0.6571735739707947\n",
      "13750 - discriminator loss: 0.6908916234970093 - adversarial loss: 0.6755729913711548\n",
      "13775 - discriminator loss: 0.691663384437561 - adversarial loss: 0.6604886054992676\n",
      "13800 - discriminator loss: 0.7003045082092285 - adversarial loss: 0.648985743522644\n",
      "13825 - discriminator loss: 0.6923936009407043 - adversarial loss: 0.6881228089332581\n",
      "13850 - discriminator loss: 0.6900191307067871 - adversarial loss: 0.6247783899307251\n",
      "13875 - discriminator loss: 0.6909781694412231 - adversarial loss: 0.6786342859268188\n",
      "13900 - discriminator loss: 0.6903492212295532 - adversarial loss: 0.6529234647750854\n",
      "13925 - discriminator loss: 0.691663384437561 - adversarial loss: 0.659064531326294\n",
      "13950 - discriminator loss: 0.7006704807281494 - adversarial loss: 0.6826180219650269\n",
      "13975 - discriminator loss: 0.6823786497116089 - adversarial loss: 0.6556702852249146\n",
      "14000 - discriminator loss: 0.691871702671051 - adversarial loss: 0.6551189422607422\n",
      "14025 - discriminator loss: 0.6976523399353027 - adversarial loss: 0.679192066192627\n",
      "14050 - discriminator loss: 0.692834734916687 - adversarial loss: 0.680094838142395\n",
      "14075 - discriminator loss: 0.6911224126815796 - adversarial loss: 0.6404624581336975\n",
      "14100 - discriminator loss: 0.679049015045166 - adversarial loss: 0.6539192199707031\n",
      "14125 - discriminator loss: 0.6972377300262451 - adversarial loss: 0.6543208360671997\n",
      "14150 - discriminator loss: 0.6989432573318481 - adversarial loss: 0.6327177286148071\n",
      "14175 - discriminator loss: 0.6954579949378967 - adversarial loss: 0.6807687282562256\n",
      "14200 - discriminator loss: 0.6965165138244629 - adversarial loss: 0.6266270279884338\n",
      "14225 - discriminator loss: 0.6948323249816895 - adversarial loss: 0.6581076979637146\n",
      "14250 - discriminator loss: 0.6873548030853271 - adversarial loss: 0.6613126993179321\n",
      "14275 - discriminator loss: 0.6933962106704712 - adversarial loss: 0.6447122097015381\n",
      "14300 - discriminator loss: 0.6920562982559204 - adversarial loss: 0.6288944482803345\n",
      "14325 - discriminator loss: 0.6948451399803162 - adversarial loss: 0.6496259570121765\n",
      "14350 - discriminator loss: 0.6988000273704529 - adversarial loss: 0.657318115234375\n",
      "14375 - discriminator loss: 0.6912050247192383 - adversarial loss: 0.6515506505966187\n",
      "14400 - discriminator loss: 0.6887455582618713 - adversarial loss: 0.6641835570335388\n",
      "14425 - discriminator loss: 0.6993883848190308 - adversarial loss: 0.6610561609268188\n",
      "14450 - discriminator loss: 0.6931939125061035 - adversarial loss: 0.641242265701294\n",
      "14475 - discriminator loss: 0.6887427568435669 - adversarial loss: 0.6214842796325684\n",
      "14500 - discriminator loss: 0.6891149282455444 - adversarial loss: 0.6847554445266724\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14525 - discriminator loss: 0.696887195110321 - adversarial loss: 0.6535478830337524\n",
      "14550 - discriminator loss: 0.6925787925720215 - adversarial loss: 0.6630197167396545\n",
      "14575 - discriminator loss: 0.6933413743972778 - adversarial loss: 0.6633814573287964\n",
      "14600 - discriminator loss: 0.6911982297897339 - adversarial loss: 0.6413143873214722\n",
      "14625 - discriminator loss: 0.6913349628448486 - adversarial loss: 0.638353705406189\n",
      "14650 - discriminator loss: 0.6938955783843994 - adversarial loss: 0.6618245840072632\n",
      "14675 - discriminator loss: 0.6878018379211426 - adversarial loss: 0.6896710991859436\n",
      "14700 - discriminator loss: 0.6956202387809753 - adversarial loss: 0.6570423245429993\n",
      "14725 - discriminator loss: 0.6970152258872986 - adversarial loss: 0.6652165055274963\n",
      "14750 - discriminator loss: 0.6896001100540161 - adversarial loss: 0.6444785594940186\n",
      "14775 - discriminator loss: 0.6949611902236938 - adversarial loss: 0.6474847197532654\n",
      "14800 - discriminator loss: 0.6922687888145447 - adversarial loss: 0.6660348176956177\n",
      "14825 - discriminator loss: 0.6904600858688354 - adversarial loss: 0.629788875579834\n",
      "14850 - discriminator loss: 0.6989118456840515 - adversarial loss: 0.6499065160751343\n",
      "14875 - discriminator loss: 0.6993599534034729 - adversarial loss: 0.629558801651001\n",
      "14900 - discriminator loss: 0.6885097622871399 - adversarial loss: 0.6282413005828857\n",
      "14925 - discriminator loss: 0.6915947198867798 - adversarial loss: 0.6657239198684692\n",
      "14950 - discriminator loss: 0.6971743106842041 - adversarial loss: 0.64715576171875\n",
      "14975 - discriminator loss: 0.6960848569869995 - adversarial loss: 0.6685523390769958\n",
      "15000 - discriminator loss: 0.693433403968811 - adversarial loss: 0.6343235969543457\n",
      "15025 - discriminator loss: 0.6886917352676392 - adversarial loss: 0.6327518224716187\n",
      "15050 - discriminator loss: 0.6921212673187256 - adversarial loss: 0.6423695683479309\n",
      "15075 - discriminator loss: 0.6910653710365295 - adversarial loss: 0.6863181591033936\n",
      "15100 - discriminator loss: 0.69266676902771 - adversarial loss: 0.6389453411102295\n",
      "15125 - discriminator loss: 0.6907874941825867 - adversarial loss: 0.6516226530075073\n",
      "15150 - discriminator loss: 0.6928895711898804 - adversarial loss: 0.6594104766845703\n",
      "15175 - discriminator loss: 0.694236159324646 - adversarial loss: 0.6615235805511475\n",
      "15200 - discriminator loss: 0.6948988437652588 - adversarial loss: 0.6482396125793457\n",
      "15225 - discriminator loss: 0.6905112862586975 - adversarial loss: 0.6480194926261902\n",
      "15250 - discriminator loss: 0.69572514295578 - adversarial loss: 0.6592474579811096\n",
      "15275 - discriminator loss: 0.6961644887924194 - adversarial loss: 0.6547725200653076\n",
      "15300 - discriminator loss: 0.6908625364303589 - adversarial loss: 0.6521975994110107\n",
      "15325 - discriminator loss: 0.6943743228912354 - adversarial loss: 0.6484119296073914\n",
      "15350 - discriminator loss: 0.6966298222541809 - adversarial loss: 0.6563872694969177\n",
      "15375 - discriminator loss: 0.6951441764831543 - adversarial loss: 0.6568870544433594\n",
      "15400 - discriminator loss: 0.6896524429321289 - adversarial loss: 0.6603243350982666\n",
      "15425 - discriminator loss: 0.6973885297775269 - adversarial loss: 0.6439988017082214\n",
      "15450 - discriminator loss: 0.6932685375213623 - adversarial loss: 0.668647825717926\n",
      "15475 - discriminator loss: 0.6963784098625183 - adversarial loss: 0.652780294418335\n",
      "15500 - discriminator loss: 0.6989167332649231 - adversarial loss: 0.64992755651474\n",
      "15525 - discriminator loss: 0.6921122074127197 - adversarial loss: 0.6600899696350098\n",
      "15550 - discriminator loss: 0.6909621953964233 - adversarial loss: 0.6636781692504883\n",
      "15575 - discriminator loss: 0.6892467141151428 - adversarial loss: 0.650799572467804\n",
      "15600 - discriminator loss: 0.6930866837501526 - adversarial loss: 0.6424401998519897\n",
      "15625 - discriminator loss: 0.6852943897247314 - adversarial loss: 0.6476837992668152\n",
      "15650 - discriminator loss: 0.6923273205757141 - adversarial loss: 0.6516928672790527\n",
      "15675 - discriminator loss: 0.6876897811889648 - adversarial loss: 0.6548200249671936\n",
      "15700 - discriminator loss: 0.693912148475647 - adversarial loss: 0.6672409772872925\n",
      "15725 - discriminator loss: 0.6933702826499939 - adversarial loss: 0.6549733877182007\n",
      "15750 - discriminator loss: 0.6934593319892883 - adversarial loss: 0.6529515981674194\n",
      "15775 - discriminator loss: 0.689985990524292 - adversarial loss: 0.6600499153137207\n",
      "15800 - discriminator loss: 0.6920464038848877 - adversarial loss: 0.6482363939285278\n",
      "15825 - discriminator loss: 0.6940675377845764 - adversarial loss: 0.6597902774810791\n",
      "15850 - discriminator loss: 0.690131425857544 - adversarial loss: 0.6437135934829712\n",
      "15875 - discriminator loss: 0.6950023174285889 - adversarial loss: 0.6409908533096313\n",
      "15900 - discriminator loss: 0.6899045705795288 - adversarial loss: 0.6635157465934753\n",
      "15925 - discriminator loss: 0.6882326006889343 - adversarial loss: 0.6539354920387268\n",
      "15950 - discriminator loss: 0.6963603496551514 - adversarial loss: 0.6366026401519775\n",
      "15975 - discriminator loss: 0.6929396390914917 - adversarial loss: 0.6414635181427002\n",
      "16000 - discriminator loss: 0.6948413252830505 - adversarial loss: 0.6462754011154175\n",
      "16025 - discriminator loss: 0.6919758915901184 - adversarial loss: 0.6554555892944336\n",
      "16050 - discriminator loss: 0.6936294436454773 - adversarial loss: 0.6797424554824829\n",
      "16075 - discriminator loss: 0.6912998557090759 - adversarial loss: 0.6634317636489868\n",
      "16100 - discriminator loss: 0.6893903613090515 - adversarial loss: 0.6356525421142578\n",
      "16125 - discriminator loss: 0.6901259422302246 - adversarial loss: 0.6542184352874756\n",
      "16150 - discriminator loss: 0.6875913143157959 - adversarial loss: 0.6408944129943848\n",
      "16175 - discriminator loss: 0.6988167762756348 - adversarial loss: 0.6548210978507996\n",
      "16200 - discriminator loss: 0.6963926553726196 - adversarial loss: 0.6533755660057068\n",
      "16225 - discriminator loss: 0.6898226737976074 - adversarial loss: 0.6408337354660034\n",
      "16250 - discriminator loss: 0.6978079080581665 - adversarial loss: 0.6520718336105347\n",
      "16275 - discriminator loss: 0.6958017945289612 - adversarial loss: 0.6521624326705933\n",
      "16300 - discriminator loss: 0.6975932121276855 - adversarial loss: 0.6384614706039429\n",
      "16325 - discriminator loss: 0.6926414966583252 - adversarial loss: 0.6354174017906189\n",
      "16350 - discriminator loss: 0.6917200684547424 - adversarial loss: 0.6239201426506042\n",
      "16375 - discriminator loss: 0.6949558258056641 - adversarial loss: 0.6520322561264038\n",
      "16400 - discriminator loss: 0.6903395652770996 - adversarial loss: 0.6468810439109802\n",
      "16425 - discriminator loss: 0.6916558742523193 - adversarial loss: 0.6414998769760132\n",
      "16450 - discriminator loss: 0.6914756894111633 - adversarial loss: 0.616581380367279\n",
      "16475 - discriminator loss: 0.6919421553611755 - adversarial loss: 0.6370621919631958\n",
      "16500 - discriminator loss: 0.6928884983062744 - adversarial loss: 0.6536462903022766\n",
      "16525 - discriminator loss: 0.69466233253479 - adversarial loss: 0.6494910717010498\n",
      "16550 - discriminator loss: 0.7025588750839233 - adversarial loss: 0.6461168527603149\n",
      "16575 - discriminator loss: 0.6948047876358032 - adversarial loss: 0.6281260251998901\n",
      "16600 - discriminator loss: 0.6897313594818115 - adversarial loss: 0.6782593727111816\n",
      "16625 - discriminator loss: 0.6958966851234436 - adversarial loss: 0.6425453424453735\n",
      "16650 - discriminator loss: 0.6931480765342712 - adversarial loss: 0.6427977085113525\n",
      "16675 - discriminator loss: 0.6929553747177124 - adversarial loss: 0.6723747253417969\n",
      "16700 - discriminator loss: 0.6938899755477905 - adversarial loss: 0.6599330902099609\n",
      "16725 - discriminator loss: 0.6876096725463867 - adversarial loss: 0.643599271774292\n",
      "16750 - discriminator loss: 0.6999613046646118 - adversarial loss: 0.6699831485748291\n",
      "16775 - discriminator loss: 0.6890095472335815 - adversarial loss: 0.6410546898841858\n",
      "16800 - discriminator loss: 0.6983476877212524 - adversarial loss: 0.6439220905303955\n",
      "16825 - discriminator loss: 0.6923452615737915 - adversarial loss: 0.6498026847839355\n",
      "16850 - discriminator loss: 0.693886399269104 - adversarial loss: 0.6667197942733765\n",
      "16875 - discriminator loss: 0.6963039040565491 - adversarial loss: 0.6291771531105042\n",
      "16900 - discriminator loss: 0.6938120722770691 - adversarial loss: 0.668077290058136\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16925 - discriminator loss: 0.693689227104187 - adversarial loss: 0.6145866513252258\n",
      "16950 - discriminator loss: 0.6911500692367554 - adversarial loss: 0.6317548751831055\n",
      "16975 - discriminator loss: 0.6945136189460754 - adversarial loss: 0.6532210111618042\n",
      "17000 - discriminator loss: 0.6870113015174866 - adversarial loss: 0.6463987827301025\n",
      "17025 - discriminator loss: 0.6896746754646301 - adversarial loss: 0.6213029623031616\n",
      "17050 - discriminator loss: 0.6902108192443848 - adversarial loss: 0.6757251620292664\n",
      "17075 - discriminator loss: 0.6942070722579956 - adversarial loss: 0.6314942240715027\n",
      "17100 - discriminator loss: 0.695408821105957 - adversarial loss: 0.6628881692886353\n",
      "17125 - discriminator loss: 0.6945217847824097 - adversarial loss: 0.6476518511772156\n",
      "17150 - discriminator loss: 0.6943165063858032 - adversarial loss: 0.6503602862358093\n",
      "17175 - discriminator loss: 0.6918833255767822 - adversarial loss: 0.6334880590438843\n",
      "17200 - discriminator loss: 0.6937310099601746 - adversarial loss: 0.6470760703086853\n",
      "17225 - discriminator loss: 0.6945983171463013 - adversarial loss: 0.6544114351272583\n",
      "17250 - discriminator loss: 0.6861137747764587 - adversarial loss: 0.6207384467124939\n",
      "17275 - discriminator loss: 0.6932344436645508 - adversarial loss: 0.6431359052658081\n",
      "17300 - discriminator loss: 0.6924523115158081 - adversarial loss: 0.6459797024726868\n",
      "17325 - discriminator loss: 0.6891304850578308 - adversarial loss: 0.6546175479888916\n",
      "17350 - discriminator loss: 0.6938635110855103 - adversarial loss: 0.6569023728370667\n",
      "17375 - discriminator loss: 0.6912180781364441 - adversarial loss: 0.6489641666412354\n",
      "17400 - discriminator loss: 0.6881265044212341 - adversarial loss: 0.6531213521957397\n",
      "17425 - discriminator loss: 0.6966891288757324 - adversarial loss: 0.6472479104995728\n",
      "17450 - discriminator loss: 0.695783257484436 - adversarial loss: 0.6373341083526611\n",
      "17475 - discriminator loss: 0.7014869451522827 - adversarial loss: 0.6654512882232666\n",
      "17500 - discriminator loss: 0.6996229887008667 - adversarial loss: 0.6161618232727051\n",
      "17525 - discriminator loss: 0.6933079361915588 - adversarial loss: 0.6434338092803955\n",
      "17550 - discriminator loss: 0.6913343667984009 - adversarial loss: 0.6370539665222168\n",
      "17575 - discriminator loss: 0.6955657601356506 - adversarial loss: 0.650027334690094\n",
      "17600 - discriminator loss: 0.6926405429840088 - adversarial loss: 0.6500235199928284\n",
      "17625 - discriminator loss: 0.6978555917739868 - adversarial loss: 0.661912202835083\n",
      "17650 - discriminator loss: 0.6945877075195312 - adversarial loss: 0.6370020508766174\n",
      "17675 - discriminator loss: 0.6978694796562195 - adversarial loss: 0.6530172824859619\n",
      "17700 - discriminator loss: 0.6913650035858154 - adversarial loss: 0.6487551331520081\n",
      "17725 - discriminator loss: 0.6922607421875 - adversarial loss: 0.637010395526886\n",
      "17750 - discriminator loss: 0.6894694566726685 - adversarial loss: 0.6454895734786987\n",
      "17775 - discriminator loss: 0.6990798115730286 - adversarial loss: 0.6476903557777405\n",
      "17800 - discriminator loss: 0.6925317645072937 - adversarial loss: 0.6436873078346252\n",
      "17825 - discriminator loss: 0.6939632892608643 - adversarial loss: 0.6538166999816895\n",
      "17850 - discriminator loss: 0.6924818754196167 - adversarial loss: 0.6775845289230347\n",
      "17875 - discriminator loss: 0.6964470148086548 - adversarial loss: 0.6348292231559753\n",
      "17900 - discriminator loss: 0.6843231916427612 - adversarial loss: 0.6522247195243835\n",
      "17925 - discriminator loss: 0.697185754776001 - adversarial loss: 0.6473755836486816\n",
      "17950 - discriminator loss: 0.6937206387519836 - adversarial loss: 0.6279435753822327\n",
      "17975 - discriminator loss: 0.6958807706832886 - adversarial loss: 0.6467313766479492\n",
      "18000 - discriminator loss: 0.6940509080886841 - adversarial loss: 0.6455607414245605\n",
      "18025 - discriminator loss: 0.6900433301925659 - adversarial loss: 0.6447427272796631\n",
      "18050 - discriminator loss: 0.6915452480316162 - adversarial loss: 0.6522607803344727\n",
      "18075 - discriminator loss: 0.6944833397865295 - adversarial loss: 0.6313837766647339\n",
      "18100 - discriminator loss: 0.692462146282196 - adversarial loss: 0.6585052013397217\n",
      "18125 - discriminator loss: 0.6949917078018188 - adversarial loss: 0.679985523223877\n",
      "18150 - discriminator loss: 0.6918138861656189 - adversarial loss: 0.6566365957260132\n",
      "18175 - discriminator loss: 0.6915043592453003 - adversarial loss: 0.6659802198410034\n",
      "18200 - discriminator loss: 0.6949182748794556 - adversarial loss: 0.6442042589187622\n",
      "18225 - discriminator loss: 0.6990666389465332 - adversarial loss: 0.6427745819091797\n",
      "18250 - discriminator loss: 0.696768045425415 - adversarial loss: 0.6590040922164917\n",
      "18275 - discriminator loss: 0.6903862357139587 - adversarial loss: 0.6392457485198975\n",
      "18300 - discriminator loss: 0.6893666982650757 - adversarial loss: 0.64517742395401\n",
      "18325 - discriminator loss: 0.691745400428772 - adversarial loss: 0.6478748321533203\n",
      "18350 - discriminator loss: 0.7001520991325378 - adversarial loss: 0.6751801371574402\n",
      "18375 - discriminator loss: 0.6941230297088623 - adversarial loss: 0.6569461822509766\n",
      "18400 - discriminator loss: 0.6942199468612671 - adversarial loss: 0.663630485534668\n",
      "18425 - discriminator loss: 0.6923184394836426 - adversarial loss: 0.6718121767044067\n",
      "18450 - discriminator loss: 0.692354142665863 - adversarial loss: 0.6430617570877075\n",
      "18475 - discriminator loss: 0.6916288137435913 - adversarial loss: 0.6508293151855469\n",
      "18500 - discriminator loss: 0.6921229362487793 - adversarial loss: 0.6401641964912415\n",
      "18525 - discriminator loss: 0.6954264640808105 - adversarial loss: 0.6426839828491211\n",
      "18550 - discriminator loss: 0.699245035648346 - adversarial loss: 0.6191084980964661\n",
      "18575 - discriminator loss: 0.6935302019119263 - adversarial loss: 0.64586341381073\n",
      "18600 - discriminator loss: 0.6924208402633667 - adversarial loss: 0.6679031848907471\n",
      "18625 - discriminator loss: 0.6941300630569458 - adversarial loss: 0.6470949649810791\n",
      "18650 - discriminator loss: 0.69389808177948 - adversarial loss: 0.6454083919525146\n",
      "18675 - discriminator loss: 0.6925846338272095 - adversarial loss: 0.6385252475738525\n",
      "18700 - discriminator loss: 0.6917769908905029 - adversarial loss: 0.6742647886276245\n",
      "18725 - discriminator loss: 0.6929685473442078 - adversarial loss: 0.6398211121559143\n",
      "18750 - discriminator loss: 0.6907255053520203 - adversarial loss: 0.661474347114563\n",
      "18775 - discriminator loss: 0.6915820837020874 - adversarial loss: 0.6679834127426147\n",
      "18800 - discriminator loss: 0.6887949705123901 - adversarial loss: 0.6530470848083496\n",
      "18825 - discriminator loss: 0.6951287984848022 - adversarial loss: 0.6500353813171387\n",
      "18850 - discriminator loss: 0.6951227784156799 - adversarial loss: 0.6553395986557007\n",
      "18875 - discriminator loss: 0.694619357585907 - adversarial loss: 0.6584607362747192\n",
      "18900 - discriminator loss: 0.6891889572143555 - adversarial loss: 0.6252011656761169\n",
      "18925 - discriminator loss: 0.6961698532104492 - adversarial loss: 0.6729198694229126\n",
      "18950 - discriminator loss: 0.6949353218078613 - adversarial loss: 0.6468949317932129\n",
      "18975 - discriminator loss: 0.6883909106254578 - adversarial loss: 0.6418474912643433\n",
      "19000 - discriminator loss: 0.7012884020805359 - adversarial loss: 0.6617532968521118\n",
      "19025 - discriminator loss: 0.684697151184082 - adversarial loss: 0.6276105642318726\n",
      "19050 - discriminator loss: 0.6887251138687134 - adversarial loss: 0.6700875759124756\n",
      "19075 - discriminator loss: 0.6927457451820374 - adversarial loss: 0.6351901292800903\n",
      "19100 - discriminator loss: 0.6950056552886963 - adversarial loss: 0.6449387669563293\n",
      "19125 - discriminator loss: 0.6960654258728027 - adversarial loss: 0.6471676826477051\n",
      "19150 - discriminator loss: 0.68924880027771 - adversarial loss: 0.6491058468818665\n",
      "19175 - discriminator loss: 0.6967824697494507 - adversarial loss: 0.6466212272644043\n",
      "19200 - discriminator loss: 0.6961997747421265 - adversarial loss: 0.6440584063529968\n",
      "19225 - discriminator loss: 0.6940295696258545 - adversarial loss: 0.655685544013977\n",
      "19250 - discriminator loss: 0.6951897144317627 - adversarial loss: 0.658097505569458\n",
      "19275 - discriminator loss: 0.6940624117851257 - adversarial loss: 0.6627036929130554\n",
      "19300 - discriminator loss: 0.6913653016090393 - adversarial loss: 0.629946231842041\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19325 - discriminator loss: 0.6957308053970337 - adversarial loss: 0.6460227966308594\n",
      "19350 - discriminator loss: 0.6917450428009033 - adversarial loss: 0.664583683013916\n",
      "19375 - discriminator loss: 0.6908226609230042 - adversarial loss: 0.6389786601066589\n",
      "19400 - discriminator loss: 0.6945744752883911 - adversarial loss: 0.6255890130996704\n",
      "19425 - discriminator loss: 0.698574960231781 - adversarial loss: 0.6681845188140869\n",
      "19450 - discriminator loss: 0.6918778419494629 - adversarial loss: 0.6224232316017151\n",
      "19475 - discriminator loss: 0.6906567811965942 - adversarial loss: 0.6602786779403687\n",
      "19500 - discriminator loss: 0.696316123008728 - adversarial loss: 0.6529629230499268\n",
      "19525 - discriminator loss: 0.6922343969345093 - adversarial loss: 0.649630069732666\n",
      "19550 - discriminator loss: 0.6938008069992065 - adversarial loss: 0.6408176422119141\n",
      "19575 - discriminator loss: 0.6922183036804199 - adversarial loss: 0.6410043239593506\n",
      "19600 - discriminator loss: 0.6915130615234375 - adversarial loss: 0.6526857614517212\n",
      "19625 - discriminator loss: 0.6930367946624756 - adversarial loss: 0.6658211350440979\n",
      "19650 - discriminator loss: 0.6907824277877808 - adversarial loss: 0.6586410999298096\n",
      "19675 - discriminator loss: 0.6924579739570618 - adversarial loss: 0.631757915019989\n",
      "19700 - discriminator loss: 0.6893449425697327 - adversarial loss: 0.6602327823638916\n",
      "19725 - discriminator loss: 0.6896551847457886 - adversarial loss: 0.6388042569160461\n",
      "19750 - discriminator loss: 0.694305419921875 - adversarial loss: 0.6686520576477051\n",
      "19775 - discriminator loss: 0.6915454268455505 - adversarial loss: 0.6393908858299255\n",
      "19800 - discriminator loss: 0.6904981732368469 - adversarial loss: 0.6584123373031616\n",
      "19825 - discriminator loss: 0.6949754953384399 - adversarial loss: 0.6760638356208801\n",
      "19850 - discriminator loss: 0.6934936046600342 - adversarial loss: 0.66680508852005\n",
      "19875 - discriminator loss: 0.6928095817565918 - adversarial loss: 0.6723116636276245\n",
      "19900 - discriminator loss: 0.694717288017273 - adversarial loss: 0.6211303472518921\n",
      "19925 - discriminator loss: 0.6963798999786377 - adversarial loss: 0.6672419309616089\n",
      "19950 - discriminator loss: 0.6882370114326477 - adversarial loss: 0.6375707983970642\n",
      "19975 - discriminator loss: 0.7039101123809814 - adversarial loss: 0.655670166015625\n",
      "19999 - discriminator loss: 0.6880626678466797 - adversarial loss: 0.6530472040176392\n"
     ]
    }
   ],
   "source": [
    "rede = rede(64, 64)\n",
    "rede.build_network()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test():\n",
    "    model = load_model('2_Generator_model_gan_64_64.h5')\n",
    "    batch_size = 128\n",
    "    random_latent_vectors = np.random.normal(size=(batch_size, 100))\n",
    "    generated_images = model.predict(random_latent_vectors)\n",
    "    images_path = os.path.join(abs_path,'2_Generated_Images_Test_64_64').replace('\\\\','/')\n",
    "    if not os.path.exists(images_path):\n",
    "        os.mkdir(images_path)\n",
    "    for index in range(batch_size):\n",
    "        img = image.array_to_img(np.squeeze(np.round((generated_images[index] * 127.5) + 127.5).astype(np.uint8)), scale=False)\n",
    "        img.save(os.path.join(images_path,'2_GAN_' + str(index+1) + '_generated_anime.png'))\n",
    "    print(\"OI\")\n",
    "#test()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Oi\n"
     ]
    }
   ],
   "source": [
    "print(\"Oi\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
